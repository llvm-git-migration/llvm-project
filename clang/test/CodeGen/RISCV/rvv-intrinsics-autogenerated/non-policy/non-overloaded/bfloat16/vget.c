// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py UTC_ARGS: --version 4
// REQUIRES: riscv-registered-target
// RUN: %clang_cc1 -triple riscv64 -target-feature +v \
// RUN:   -target-feature +experimental-zvfbfmin \
// RUN:   -target-feature +experimental-zvfbfwma -disable-O0-optnone \
// RUN:   -emit-llvm %s -o - | opt -S -passes=mem2reg | \
// RUN:   FileCheck --check-prefix=CHECK-RV64 %s

#include <riscv_vector.h>

// CHECK-RV64-LABEL: define dso_local <vscale x 4 x bfloat> @test_vget_v_bf16m2_bf16m1(
// CHECK-RV64-SAME: <vscale x 8 x bfloat> [[SRC:%.*]], i64 noundef [[INDEX:%.*]]) #[[ATTR0:[0-9]+]] {
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = call <vscale x 4 x bfloat> @llvm.vector.extract.nxv4bf16.nxv8bf16(<vscale x 8 x bfloat> [[SRC]], i64 0)
// CHECK-RV64-NEXT:    ret <vscale x 4 x bfloat> [[TMP0]]
//
vbfloat16m1_t test_vget_v_bf16m2_bf16m1(vbfloat16m2_t src, size_t index) {
  return __riscv_vget_v_bf16m2_bf16m1(src, 0);
}

// CHECK-RV64-LABEL: define dso_local <vscale x 4 x bfloat> @test_vget_v_bf16m4_bf16m1(
// CHECK-RV64-SAME: <vscale x 16 x bfloat> [[SRC:%.*]], i64 noundef [[INDEX:%.*]]) #[[ATTR0]] {
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = call <vscale x 4 x bfloat> @llvm.vector.extract.nxv4bf16.nxv16bf16(<vscale x 16 x bfloat> [[SRC]], i64 0)
// CHECK-RV64-NEXT:    ret <vscale x 4 x bfloat> [[TMP0]]
//
vbfloat16m1_t test_vget_v_bf16m4_bf16m1(vbfloat16m4_t src, size_t index) {
  return __riscv_vget_v_bf16m4_bf16m1(src, 0);
}

// CHECK-RV64-LABEL: define dso_local <vscale x 4 x bfloat> @test_vget_v_bf16m8_bf16m1(
// CHECK-RV64-SAME: <vscale x 32 x bfloat> [[SRC:%.*]], i64 noundef [[INDEX:%.*]]) #[[ATTR0]] {
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = call <vscale x 4 x bfloat> @llvm.vector.extract.nxv4bf16.nxv32bf16(<vscale x 32 x bfloat> [[SRC]], i64 0)
// CHECK-RV64-NEXT:    ret <vscale x 4 x bfloat> [[TMP0]]
//
vbfloat16m1_t test_vget_v_bf16m8_bf16m1(vbfloat16m8_t src, size_t index) {
  return __riscv_vget_v_bf16m8_bf16m1(src, 0);
}

// CHECK-RV64-LABEL: define dso_local <vscale x 8 x bfloat> @test_vget_v_bf16m4_bf16m2(
// CHECK-RV64-SAME: <vscale x 16 x bfloat> [[SRC:%.*]], i64 noundef [[INDEX:%.*]]) #[[ATTR0]] {
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = call <vscale x 8 x bfloat> @llvm.vector.extract.nxv8bf16.nxv16bf16(<vscale x 16 x bfloat> [[SRC]], i64 0)
// CHECK-RV64-NEXT:    ret <vscale x 8 x bfloat> [[TMP0]]
//
vbfloat16m2_t test_vget_v_bf16m4_bf16m2(vbfloat16m4_t src, size_t index) {
  return __riscv_vget_v_bf16m4_bf16m2(src, 0);
}

// CHECK-RV64-LABEL: define dso_local <vscale x 8 x bfloat> @test_vget_v_bf16m8_bf16m2(
// CHECK-RV64-SAME: <vscale x 32 x bfloat> [[SRC:%.*]], i64 noundef [[INDEX:%.*]]) #[[ATTR0]] {
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = call <vscale x 8 x bfloat> @llvm.vector.extract.nxv8bf16.nxv32bf16(<vscale x 32 x bfloat> [[SRC]], i64 0)
// CHECK-RV64-NEXT:    ret <vscale x 8 x bfloat> [[TMP0]]
//
vbfloat16m2_t test_vget_v_bf16m8_bf16m2(vbfloat16m8_t src, size_t index) {
  return __riscv_vget_v_bf16m8_bf16m2(src, 0);
}

// CHECK-RV64-LABEL: define dso_local <vscale x 16 x bfloat> @test_vget_v_bf16m8_bf16m4(
// CHECK-RV64-SAME: <vscale x 32 x bfloat> [[SRC:%.*]], i64 noundef [[INDEX:%.*]]) #[[ATTR0]] {
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = call <vscale x 16 x bfloat> @llvm.vector.extract.nxv16bf16.nxv32bf16(<vscale x 32 x bfloat> [[SRC]], i64 0)
// CHECK-RV64-NEXT:    ret <vscale x 16 x bfloat> [[TMP0]]
//
vbfloat16m4_t test_vget_v_bf16m8_bf16m4(vbfloat16m8_t src, size_t index) {
  return __riscv_vget_v_bf16m8_bf16m4(src, 0);
}

// CHECK-RV64-LABEL: define dso_local <vscale x 1 x bfloat> @test_vget_v_bf16mf4x2_bf16mf4(
// CHECK-RV64-SAME: target("riscv_mf4x2", i8, i8, 1, 2) [[SRC:%.*]], i64 noundef [[INDEX:%.*]]) #[[ATTR0]] {
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = call <vscale x 1 x bfloat> @llvm.riscv.vector.extract.nxv1bf16.triscv_mf4x2_i8_i8_1_2t.i64(target("riscv_mf4x2", i8, i8, 1, 2) [[SRC]], i64 0)
// CHECK-RV64-NEXT:    ret <vscale x 1 x bfloat> [[TMP0]]
//
vbfloat16mf4_t test_vget_v_bf16mf4x2_bf16mf4(vbfloat16mf4x2_t src,
                                             size_t index) {
  return __riscv_vget_v_bf16mf4x2_bf16mf4(src, 0);
}

// CHECK-RV64-LABEL: define dso_local <vscale x 1 x bfloat> @test_vget_v_bf16mf4x3_bf16mf4(
// CHECK-RV64-SAME: target("riscv_mf4x3", i8, i8, 1, 3) [[SRC:%.*]], i64 noundef [[INDEX:%.*]]) #[[ATTR0]] {
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = call <vscale x 1 x bfloat> @llvm.riscv.vector.extract.nxv1bf16.triscv_mf4x3_i8_i8_1_3t.i64(target("riscv_mf4x3", i8, i8, 1, 3) [[SRC]], i64 0)
// CHECK-RV64-NEXT:    ret <vscale x 1 x bfloat> [[TMP0]]
//
vbfloat16mf4_t test_vget_v_bf16mf4x3_bf16mf4(vbfloat16mf4x3_t src,
                                             size_t index) {
  return __riscv_vget_v_bf16mf4x3_bf16mf4(src, 0);
}

// CHECK-RV64-LABEL: define dso_local <vscale x 1 x bfloat> @test_vget_v_bf16mf4x4_bf16mf4(
// CHECK-RV64-SAME: target("riscv_mf4x4", i8, i8, 1, 4) [[SRC:%.*]], i64 noundef [[INDEX:%.*]]) #[[ATTR0]] {
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = call <vscale x 1 x bfloat> @llvm.riscv.vector.extract.nxv1bf16.triscv_mf4x4_i8_i8_1_4t.i64(target("riscv_mf4x4", i8, i8, 1, 4) [[SRC]], i64 0)
// CHECK-RV64-NEXT:    ret <vscale x 1 x bfloat> [[TMP0]]
//
vbfloat16mf4_t test_vget_v_bf16mf4x4_bf16mf4(vbfloat16mf4x4_t src,
                                             size_t index) {
  return __riscv_vget_v_bf16mf4x4_bf16mf4(src, 0);
}

// CHECK-RV64-LABEL: define dso_local <vscale x 1 x bfloat> @test_vget_v_bf16mf4x5_bf16mf4(
// CHECK-RV64-SAME: target("riscv_mf4x5", i8, i8, 1, 5) [[SRC:%.*]], i64 noundef [[INDEX:%.*]]) #[[ATTR0]] {
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = call <vscale x 1 x bfloat> @llvm.riscv.vector.extract.nxv1bf16.triscv_mf4x5_i8_i8_1_5t.i64(target("riscv_mf4x5", i8, i8, 1, 5) [[SRC]], i64 0)
// CHECK-RV64-NEXT:    ret <vscale x 1 x bfloat> [[TMP0]]
//
vbfloat16mf4_t test_vget_v_bf16mf4x5_bf16mf4(vbfloat16mf4x5_t src,
                                             size_t index) {
  return __riscv_vget_v_bf16mf4x5_bf16mf4(src, 0);
}

// CHECK-RV64-LABEL: define dso_local <vscale x 1 x bfloat> @test_vget_v_bf16mf4x6_bf16mf4(
// CHECK-RV64-SAME: target("riscv_mf4x6", i8, i8, 1, 6) [[SRC:%.*]], i64 noundef [[INDEX:%.*]]) #[[ATTR0]] {
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = call <vscale x 1 x bfloat> @llvm.riscv.vector.extract.nxv1bf16.triscv_mf4x6_i8_i8_1_6t.i64(target("riscv_mf4x6", i8, i8, 1, 6) [[SRC]], i64 0)
// CHECK-RV64-NEXT:    ret <vscale x 1 x bfloat> [[TMP0]]
//
vbfloat16mf4_t test_vget_v_bf16mf4x6_bf16mf4(vbfloat16mf4x6_t src,
                                             size_t index) {
  return __riscv_vget_v_bf16mf4x6_bf16mf4(src, 0);
}

// CHECK-RV64-LABEL: define dso_local <vscale x 1 x bfloat> @test_vget_v_bf16mf4x7_bf16mf4(
// CHECK-RV64-SAME: target("riscv_mf4x7", i8, i8, 1, 7) [[SRC:%.*]], i64 noundef [[INDEX:%.*]]) #[[ATTR0]] {
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = call <vscale x 1 x bfloat> @llvm.riscv.vector.extract.nxv1bf16.triscv_mf4x7_i8_i8_1_7t.i64(target("riscv_mf4x7", i8, i8, 1, 7) [[SRC]], i64 0)
// CHECK-RV64-NEXT:    ret <vscale x 1 x bfloat> [[TMP0]]
//
vbfloat16mf4_t test_vget_v_bf16mf4x7_bf16mf4(vbfloat16mf4x7_t src,
                                             size_t index) {
  return __riscv_vget_v_bf16mf4x7_bf16mf4(src, 0);
}

// CHECK-RV64-LABEL: define dso_local <vscale x 1 x bfloat> @test_vget_v_bf16mf4x8_bf16mf4(
// CHECK-RV64-SAME: target("riscv_mf4x8", i8, i8, 1, 8) [[SRC:%.*]], i64 noundef [[INDEX:%.*]]) #[[ATTR0]] {
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = call <vscale x 1 x bfloat> @llvm.riscv.vector.extract.nxv1bf16.triscv_mf4x8_i8_i8_1_8t.i64(target("riscv_mf4x8", i8, i8, 1, 8) [[SRC]], i64 0)
// CHECK-RV64-NEXT:    ret <vscale x 1 x bfloat> [[TMP0]]
//
vbfloat16mf4_t test_vget_v_bf16mf4x8_bf16mf4(vbfloat16mf4x8_t src,
                                             size_t index) {
  return __riscv_vget_v_bf16mf4x8_bf16mf4(src, 0);
}

// CHECK-RV64-LABEL: define dso_local <vscale x 2 x bfloat> @test_vget_v_bf16mf2x2_bf16mf2(
// CHECK-RV64-SAME: target("riscv_mf2x2", i8, i8, 2, 2) [[SRC:%.*]], i64 noundef [[INDEX:%.*]]) #[[ATTR0]] {
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = call <vscale x 2 x bfloat> @llvm.riscv.vector.extract.nxv2bf16.triscv_mf2x2_i8_i8_2_2t.i64(target("riscv_mf2x2", i8, i8, 2, 2) [[SRC]], i64 0)
// CHECK-RV64-NEXT:    ret <vscale x 2 x bfloat> [[TMP0]]
//
vbfloat16mf2_t test_vget_v_bf16mf2x2_bf16mf2(vbfloat16mf2x2_t src,
                                             size_t index) {
  return __riscv_vget_v_bf16mf2x2_bf16mf2(src, 0);
}

// CHECK-RV64-LABEL: define dso_local <vscale x 2 x bfloat> @test_vget_v_bf16mf2x3_bf16mf2(
// CHECK-RV64-SAME: target("riscv_mf2x3", i8, i8, 2, 3) [[SRC:%.*]], i64 noundef [[INDEX:%.*]]) #[[ATTR0]] {
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = call <vscale x 2 x bfloat> @llvm.riscv.vector.extract.nxv2bf16.triscv_mf2x3_i8_i8_2_3t.i64(target("riscv_mf2x3", i8, i8, 2, 3) [[SRC]], i64 0)
// CHECK-RV64-NEXT:    ret <vscale x 2 x bfloat> [[TMP0]]
//
vbfloat16mf2_t test_vget_v_bf16mf2x3_bf16mf2(vbfloat16mf2x3_t src,
                                             size_t index) {
  return __riscv_vget_v_bf16mf2x3_bf16mf2(src, 0);
}

// CHECK-RV64-LABEL: define dso_local <vscale x 2 x bfloat> @test_vget_v_bf16mf2x4_bf16mf2(
// CHECK-RV64-SAME: target("riscv_mf2x4", i8, i8, 2, 4) [[SRC:%.*]], i64 noundef [[INDEX:%.*]]) #[[ATTR0]] {
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = call <vscale x 2 x bfloat> @llvm.riscv.vector.extract.nxv2bf16.triscv_mf2x4_i8_i8_2_4t.i64(target("riscv_mf2x4", i8, i8, 2, 4) [[SRC]], i64 0)
// CHECK-RV64-NEXT:    ret <vscale x 2 x bfloat> [[TMP0]]
//
vbfloat16mf2_t test_vget_v_bf16mf2x4_bf16mf2(vbfloat16mf2x4_t src,
                                             size_t index) {
  return __riscv_vget_v_bf16mf2x4_bf16mf2(src, 0);
}

// CHECK-RV64-LABEL: define dso_local <vscale x 2 x bfloat> @test_vget_v_bf16mf2x5_bf16mf2(
// CHECK-RV64-SAME: target("riscv_mf2x5", i8, i8, 2, 5) [[SRC:%.*]], i64 noundef [[INDEX:%.*]]) #[[ATTR0]] {
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = call <vscale x 2 x bfloat> @llvm.riscv.vector.extract.nxv2bf16.triscv_mf2x5_i8_i8_2_5t.i64(target("riscv_mf2x5", i8, i8, 2, 5) [[SRC]], i64 0)
// CHECK-RV64-NEXT:    ret <vscale x 2 x bfloat> [[TMP0]]
//
vbfloat16mf2_t test_vget_v_bf16mf2x5_bf16mf2(vbfloat16mf2x5_t src,
                                             size_t index) {
  return __riscv_vget_v_bf16mf2x5_bf16mf2(src, 0);
}

// CHECK-RV64-LABEL: define dso_local <vscale x 2 x bfloat> @test_vget_v_bf16mf2x6_bf16mf2(
// CHECK-RV64-SAME: target("riscv_mf2x6", i8, i8, 2, 6) [[SRC:%.*]], i64 noundef [[INDEX:%.*]]) #[[ATTR0]] {
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = call <vscale x 2 x bfloat> @llvm.riscv.vector.extract.nxv2bf16.triscv_mf2x6_i8_i8_2_6t.i64(target("riscv_mf2x6", i8, i8, 2, 6) [[SRC]], i64 0)
// CHECK-RV64-NEXT:    ret <vscale x 2 x bfloat> [[TMP0]]
//
vbfloat16mf2_t test_vget_v_bf16mf2x6_bf16mf2(vbfloat16mf2x6_t src,
                                             size_t index) {
  return __riscv_vget_v_bf16mf2x6_bf16mf2(src, 0);
}

// CHECK-RV64-LABEL: define dso_local <vscale x 2 x bfloat> @test_vget_v_bf16mf2x7_bf16mf2(
// CHECK-RV64-SAME: target("riscv_mf2x7", i8, i8, 2, 7) [[SRC:%.*]], i64 noundef [[INDEX:%.*]]) #[[ATTR0]] {
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = call <vscale x 2 x bfloat> @llvm.riscv.vector.extract.nxv2bf16.triscv_mf2x7_i8_i8_2_7t.i64(target("riscv_mf2x7", i8, i8, 2, 7) [[SRC]], i64 0)
// CHECK-RV64-NEXT:    ret <vscale x 2 x bfloat> [[TMP0]]
//
vbfloat16mf2_t test_vget_v_bf16mf2x7_bf16mf2(vbfloat16mf2x7_t src,
                                             size_t index) {
  return __riscv_vget_v_bf16mf2x7_bf16mf2(src, 0);
}

// CHECK-RV64-LABEL: define dso_local <vscale x 2 x bfloat> @test_vget_v_bf16mf2x8_bf16mf2(
// CHECK-RV64-SAME: target("riscv_mf2x8", i8, i8, 2, 8) [[SRC:%.*]], i64 noundef [[INDEX:%.*]]) #[[ATTR0]] {
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = call <vscale x 2 x bfloat> @llvm.riscv.vector.extract.nxv2bf16.triscv_mf2x8_i8_i8_2_8t.i64(target("riscv_mf2x8", i8, i8, 2, 8) [[SRC]], i64 0)
// CHECK-RV64-NEXT:    ret <vscale x 2 x bfloat> [[TMP0]]
//
vbfloat16mf2_t test_vget_v_bf16mf2x8_bf16mf2(vbfloat16mf2x8_t src,
                                             size_t index) {
  return __riscv_vget_v_bf16mf2x8_bf16mf2(src, 0);
}

// CHECK-RV64-LABEL: define dso_local <vscale x 4 x bfloat> @test_vget_v_bf16m1x2_bf16m1(
// CHECK-RV64-SAME: target("riscv_m1x2", i8, i8, 3, 2) [[SRC:%.*]], i64 noundef [[INDEX:%.*]]) #[[ATTR0]] {
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = call <vscale x 4 x bfloat> @llvm.riscv.vector.extract.nxv4bf16.triscv_m1x2_i8_i8_3_2t.i64(target("riscv_m1x2", i8, i8, 3, 2) [[SRC]], i64 0)
// CHECK-RV64-NEXT:    ret <vscale x 4 x bfloat> [[TMP0]]
//
vbfloat16m1_t test_vget_v_bf16m1x2_bf16m1(vbfloat16m1x2_t src, size_t index) {
  return __riscv_vget_v_bf16m1x2_bf16m1(src, 0);
}

// CHECK-RV64-LABEL: define dso_local <vscale x 4 x bfloat> @test_vget_v_bf16m1x3_bf16m1(
// CHECK-RV64-SAME: target("riscv_m1x3", i8, i8, 3, 3) [[SRC:%.*]], i64 noundef [[INDEX:%.*]]) #[[ATTR0]] {
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = call <vscale x 4 x bfloat> @llvm.riscv.vector.extract.nxv4bf16.triscv_m1x3_i8_i8_3_3t.i64(target("riscv_m1x3", i8, i8, 3, 3) [[SRC]], i64 0)
// CHECK-RV64-NEXT:    ret <vscale x 4 x bfloat> [[TMP0]]
//
vbfloat16m1_t test_vget_v_bf16m1x3_bf16m1(vbfloat16m1x3_t src, size_t index) {
  return __riscv_vget_v_bf16m1x3_bf16m1(src, 0);
}

// CHECK-RV64-LABEL: define dso_local <vscale x 4 x bfloat> @test_vget_v_bf16m1x4_bf16m1(
// CHECK-RV64-SAME: target("riscv_m1x4", i8, i8, 3, 4) [[SRC:%.*]], i64 noundef [[INDEX:%.*]]) #[[ATTR0]] {
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = call <vscale x 4 x bfloat> @llvm.riscv.vector.extract.nxv4bf16.triscv_m1x4_i8_i8_3_4t.i64(target("riscv_m1x4", i8, i8, 3, 4) [[SRC]], i64 0)
// CHECK-RV64-NEXT:    ret <vscale x 4 x bfloat> [[TMP0]]
//
vbfloat16m1_t test_vget_v_bf16m1x4_bf16m1(vbfloat16m1x4_t src, size_t index) {
  return __riscv_vget_v_bf16m1x4_bf16m1(src, 0);
}

// CHECK-RV64-LABEL: define dso_local <vscale x 4 x bfloat> @test_vget_v_bf16m1x5_bf16m1(
// CHECK-RV64-SAME: target("riscv_m1x5", i8, i8, 3, 5) [[SRC:%.*]], i64 noundef [[INDEX:%.*]]) #[[ATTR0]] {
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = call <vscale x 4 x bfloat> @llvm.riscv.vector.extract.nxv4bf16.triscv_m1x5_i8_i8_3_5t.i64(target("riscv_m1x5", i8, i8, 3, 5) [[SRC]], i64 0)
// CHECK-RV64-NEXT:    ret <vscale x 4 x bfloat> [[TMP0]]
//
vbfloat16m1_t test_vget_v_bf16m1x5_bf16m1(vbfloat16m1x5_t src, size_t index) {
  return __riscv_vget_v_bf16m1x5_bf16m1(src, 0);
}

// CHECK-RV64-LABEL: define dso_local <vscale x 4 x bfloat> @test_vget_v_bf16m1x6_bf16m1(
// CHECK-RV64-SAME: target("riscv_m1x6", i8, i8, 3, 6) [[SRC:%.*]], i64 noundef [[INDEX:%.*]]) #[[ATTR0]] {
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = call <vscale x 4 x bfloat> @llvm.riscv.vector.extract.nxv4bf16.triscv_m1x6_i8_i8_3_6t.i64(target("riscv_m1x6", i8, i8, 3, 6) [[SRC]], i64 0)
// CHECK-RV64-NEXT:    ret <vscale x 4 x bfloat> [[TMP0]]
//
vbfloat16m1_t test_vget_v_bf16m1x6_bf16m1(vbfloat16m1x6_t src, size_t index) {
  return __riscv_vget_v_bf16m1x6_bf16m1(src, 0);
}

// CHECK-RV64-LABEL: define dso_local <vscale x 4 x bfloat> @test_vget_v_bf16m1x7_bf16m1(
// CHECK-RV64-SAME: target("riscv_m1x7", i8, i8, 3, 7) [[SRC:%.*]], i64 noundef [[INDEX:%.*]]) #[[ATTR0]] {
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = call <vscale x 4 x bfloat> @llvm.riscv.vector.extract.nxv4bf16.triscv_m1x7_i8_i8_3_7t.i64(target("riscv_m1x7", i8, i8, 3, 7) [[SRC]], i64 0)
// CHECK-RV64-NEXT:    ret <vscale x 4 x bfloat> [[TMP0]]
//
vbfloat16m1_t test_vget_v_bf16m1x7_bf16m1(vbfloat16m1x7_t src, size_t index) {
  return __riscv_vget_v_bf16m1x7_bf16m1(src, 0);
}

// CHECK-RV64-LABEL: define dso_local <vscale x 4 x bfloat> @test_vget_v_bf16m1x8_bf16m1(
// CHECK-RV64-SAME: target("riscv_m1x8", i8, i8, 3, 8) [[SRC:%.*]], i64 noundef [[INDEX:%.*]]) #[[ATTR0]] {
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = call <vscale x 4 x bfloat> @llvm.riscv.vector.extract.nxv4bf16.triscv_m1x8_i8_i8_3_8t.i64(target("riscv_m1x8", i8, i8, 3, 8) [[SRC]], i64 0)
// CHECK-RV64-NEXT:    ret <vscale x 4 x bfloat> [[TMP0]]
//
vbfloat16m1_t test_vget_v_bf16m1x8_bf16m1(vbfloat16m1x8_t src, size_t index) {
  return __riscv_vget_v_bf16m1x8_bf16m1(src, 0);
}

// CHECK-RV64-LABEL: define dso_local <vscale x 8 x bfloat> @test_vget_v_bf16m2x2_bf16m2(
// CHECK-RV64-SAME: target("riscv_m2x2", i8, i8, 4, 2) [[SRC:%.*]], i64 noundef [[INDEX:%.*]]) #[[ATTR0]] {
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = call <vscale x 8 x bfloat> @llvm.riscv.vector.extract.nxv8bf16.triscv_m2x2_i8_i8_4_2t.i64(target("riscv_m2x2", i8, i8, 4, 2) [[SRC]], i64 0)
// CHECK-RV64-NEXT:    ret <vscale x 8 x bfloat> [[TMP0]]
//
vbfloat16m2_t test_vget_v_bf16m2x2_bf16m2(vbfloat16m2x2_t src, size_t index) {
  return __riscv_vget_v_bf16m2x2_bf16m2(src, 0);
}

// CHECK-RV64-LABEL: define dso_local <vscale x 8 x bfloat> @test_vget_v_bf16m2x3_bf16m2(
// CHECK-RV64-SAME: target("riscv_m2x3", i8, i8, 4, 3) [[SRC:%.*]], i64 noundef [[INDEX:%.*]]) #[[ATTR0]] {
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = call <vscale x 8 x bfloat> @llvm.riscv.vector.extract.nxv8bf16.triscv_m2x3_i8_i8_4_3t.i64(target("riscv_m2x3", i8, i8, 4, 3) [[SRC]], i64 0)
// CHECK-RV64-NEXT:    ret <vscale x 8 x bfloat> [[TMP0]]
//
vbfloat16m2_t test_vget_v_bf16m2x3_bf16m2(vbfloat16m2x3_t src, size_t index) {
  return __riscv_vget_v_bf16m2x3_bf16m2(src, 0);
}

// CHECK-RV64-LABEL: define dso_local <vscale x 8 x bfloat> @test_vget_v_bf16m2x4_bf16m2(
// CHECK-RV64-SAME: target("riscv_m2x4", i8, i8, 4, 4) [[SRC:%.*]], i64 noundef [[INDEX:%.*]]) #[[ATTR0]] {
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = call <vscale x 8 x bfloat> @llvm.riscv.vector.extract.nxv8bf16.triscv_m2x4_i8_i8_4_4t.i64(target("riscv_m2x4", i8, i8, 4, 4) [[SRC]], i64 0)
// CHECK-RV64-NEXT:    ret <vscale x 8 x bfloat> [[TMP0]]
//
vbfloat16m2_t test_vget_v_bf16m2x4_bf16m2(vbfloat16m2x4_t src, size_t index) {
  return __riscv_vget_v_bf16m2x4_bf16m2(src, 0);
}

// CHECK-RV64-LABEL: define dso_local <vscale x 16 x bfloat> @test_vget_v_bf16m4x2_bf16m4(
// CHECK-RV64-SAME: target("riscv_m4x2", i8, i8, 5, 2) [[SRC:%.*]], i64 noundef [[INDEX:%.*]]) #[[ATTR0]] {
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = call <vscale x 16 x bfloat> @llvm.riscv.vector.extract.nxv16bf16.triscv_m4x2_i8_i8_5_2t.i64(target("riscv_m4x2", i8, i8, 5, 2) [[SRC]], i64 0)
// CHECK-RV64-NEXT:    ret <vscale x 16 x bfloat> [[TMP0]]
//
vbfloat16m4_t test_vget_v_bf16m4x2_bf16m4(vbfloat16m4x2_t src, size_t index) {
  return __riscv_vget_v_bf16m4x2_bf16m4(src, 0);
}
