// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py UTC_ARGS: --version 4
// RUN: %clang_cc1 -flax-vector-conversions=none -ffreestanding %s -triple=x86_64-apple-darwin -target-feature +avx2 -emit-llvm -o - -Wall -Werror | FileCheck %s --check-prefixes=CHECK,X64
// RUN: %clang_cc1 -flax-vector-conversions=none -ffreestanding %s -triple=x86_64-apple-darwin -target-feature +avx2 -fno-signed-char -emit-llvm -o - -Wall -Werror | FileCheck %s --check-prefixes=CHECK,X64
// RUN: %clang_cc1 -flax-vector-conversions=none -ffreestanding %s -triple=i386-apple-darwin -target-feature +avx2 -emit-llvm -o - -Wall -Werror | FileCheck %s --check-prefixes=CHECK,X86
// RUN: %clang_cc1 -flax-vector-conversions=none -ffreestanding %s -triple=i386-apple-darwin -target-feature +avx2 -fno-signed-char -emit-llvm -o - -Wall -Werror | FileCheck %s --check-prefixes=CHECK,X86


#include <immintrin.h>

// NOTE: This should match the tests in llvm/test/CodeGen/X86/avx2-intrinsics-fast-isel.ll

__m256i test_mm256_abs_epi8(__m256i a) {
  return _mm256_abs_epi8(a);
}

__m256i test_mm256_abs_epi16(__m256i a) {
  return _mm256_abs_epi16(a);
}

__m256i test_mm256_abs_epi32(__m256i a) {
  return _mm256_abs_epi32(a);
}

__m256i test_mm256_add_epi8(__m256i a, __m256i b) {
  return _mm256_add_epi8(a, b);
}

__m256i test_mm256_add_epi16(__m256i a, __m256i b) {
  return _mm256_add_epi16(a, b);
}

__m256i test_mm256_add_epi32(__m256i a, __m256i b) {
  return _mm256_add_epi32(a, b);
}

__m256i test_mm256_add_epi64(__m256i a, __m256i b) {
  return _mm256_add_epi64(a, b);
}

__m256i test_mm256_adds_epi8(__m256i a, __m256i b) {
  return _mm256_adds_epi8(a, b);
}

__m256i test_mm256_adds_epi16(__m256i a, __m256i b) {
  return _mm256_adds_epi16(a, b);
}

__m256i test_mm256_adds_epu8(__m256i a, __m256i b) {
  return _mm256_adds_epu8(a, b);
}

__m256i test_mm256_adds_epu16(__m256i a, __m256i b) {
  return _mm256_adds_epu16(a, b);
}

__m256i test_mm256_alignr_epi8(__m256i a, __m256i b) {
  return _mm256_alignr_epi8(a, b, 2);
}

__m256i test2_mm256_alignr_epi8(__m256i a, __m256i b) {
  return _mm256_alignr_epi8(a, b, 17);
}

__m256i test_mm256_and_si256(__m256i a, __m256i b) {
  return _mm256_and_si256(a, b);
}

__m256i test_mm256_andnot_si256(__m256i a, __m256i b) {
  return _mm256_andnot_si256(a, b);
}

__m256i test_mm256_avg_epu8(__m256i a, __m256i b) {
  return _mm256_avg_epu8(a, b);
}

__m256i test_mm256_avg_epu16(__m256i a, __m256i b) {
  return _mm256_avg_epu16(a, b);
}

// FIXME: We should also lower the __builtin_ia32_pblendw128 (and similar)
// functions to this IR. In the future we could delete the corresponding
// intrinsic in LLVM if it's not being used anymore.
__m256i test_mm256_blend_epi16(__m256i a, __m256i b) {
  return _mm256_blend_epi16(a, b, 2);
}

__m128i test_mm_blend_epi32(__m128i a, __m128i b) {
  return _mm_blend_epi32(a, b, 0x05);
}

__m256i test_mm256_blend_epi32(__m256i a, __m256i b) {
  return _mm256_blend_epi32(a, b, 0x35);
}

__m256i test_mm256_blendv_epi8(__m256i a, __m256i b, __m256i m) {
  return _mm256_blendv_epi8(a, b, m);
}

__m128i test_mm_broadcastb_epi8(__m128i a) {
  return _mm_broadcastb_epi8(a);
}

__m256i test_mm256_broadcastb_epi8(__m128i a) {
  return _mm256_broadcastb_epi8(a);
}

__m128i test_mm_broadcastd_epi32(__m128i a) {
  return _mm_broadcastd_epi32(a);
}

__m256i test_mm256_broadcastd_epi32(__m128i a) {
  return _mm256_broadcastd_epi32(a);
}

__m128i test_mm_broadcastq_epi64(__m128i a) {
  return _mm_broadcastq_epi64(a);
}

__m256i test_mm256_broadcastq_epi64(__m128i a) {
  return _mm256_broadcastq_epi64(a);
}

__m128d test_mm_broadcastsd_pd(__m128d a) {
  return _mm_broadcastsd_pd(a);
}

__m256d test_mm256_broadcastsd_pd(__m128d a) {
  return _mm256_broadcastsd_pd(a);
}

__m256i test_mm256_broadcastsi128_si256(__m128i a) {
  return _mm256_broadcastsi128_si256(a);
}

__m256i test_mm_broadcastsi128_si256(__m128i a) {
  return _mm_broadcastsi128_si256(a);
}

__m128 test_mm_broadcastss_ps(__m128 a) {
  return _mm_broadcastss_ps(a);
}

__m256 test_mm256_broadcastss_ps(__m128 a) {
  return _mm256_broadcastss_ps(a);
}

__m128i test_mm_broadcastw_epi16(__m128i a) {
  return _mm_broadcastw_epi16(a);
}

__m256i test_mm256_broadcastw_epi16(__m128i a) {
  return _mm256_broadcastw_epi16(a);
}

__m256i test_mm256_bslli_epi128(__m256i a) {
  return _mm256_bslli_epi128(a, 3);
}

__m256i test_mm256_bsrli_epi128(__m256i a) {
  return _mm256_bsrli_epi128(a, 3);
}

__m256i test_mm256_cmpeq_epi8(__m256i a, __m256i b) {
  return _mm256_cmpeq_epi8(a, b);
}

__m256i test_mm256_cmpeq_epi16(__m256i a, __m256i b) {
  return _mm256_cmpeq_epi16(a, b);
}

__m256i test_mm256_cmpeq_epi32(__m256i a, __m256i b) {
  return _mm256_cmpeq_epi32(a, b);
}

__m256i test_mm256_cmpeq_epi64(__m256i a, __m256i b) {
  return _mm256_cmpeq_epi64(a, b);
}

__m256i test_mm256_cmpgt_epi8(__m256i a, __m256i b) {
  return _mm256_cmpgt_epi8(a, b);
}

__m256i test_mm256_cmpgt_epi16(__m256i a, __m256i b) {
  return _mm256_cmpgt_epi16(a, b);
}

__m256i test_mm256_cmpgt_epi32(__m256i a, __m256i b) {
  return _mm256_cmpgt_epi32(a, b);
}

__m256i test_mm256_cmpgt_epi64(__m256i a, __m256i b) {
  return _mm256_cmpgt_epi64(a, b);
}

__m256i test_mm256_cvtepi8_epi16(__m128i a) {
  return _mm256_cvtepi8_epi16(a);
}

__m256i test_mm256_cvtepi8_epi32(__m128i a) {
  return _mm256_cvtepi8_epi32(a);
}

__m256i test_mm256_cvtepi8_epi64(__m128i a) {
  return _mm256_cvtepi8_epi64(a);
}

__m256i test_mm256_cvtepi16_epi32(__m128i a) {
  return _mm256_cvtepi16_epi32(a);
}

__m256i test_mm256_cvtepi16_epi64(__m128i a) {
  return _mm256_cvtepi16_epi64(a);
}

__m256i test_mm256_cvtepi32_epi64(__m128i a) {
  return _mm256_cvtepi32_epi64(a);
}

__m256i test_mm256_cvtepu8_epi16(__m128i a) {
  return _mm256_cvtepu8_epi16(a);
}

__m256i test_mm256_cvtepu8_epi32(__m128i a) {
  return _mm256_cvtepu8_epi32(a);
}

__m256i test_mm256_cvtepu8_epi64(__m128i a) {
  return _mm256_cvtepu8_epi64(a);
}

__m256i test_mm256_cvtepu16_epi32(__m128i a) {
  return _mm256_cvtepu16_epi32(a);
}

__m256i test_mm256_cvtepu16_epi64(__m128i a) {
  return _mm256_cvtepu16_epi64(a);
}

__m256i test_mm256_cvtepu32_epi64(__m128i a) {
  return _mm256_cvtepu32_epi64(a);
}

__m128i test0_mm256_extracti128_si256_0(__m256i a) {
  return _mm256_extracti128_si256(a, 0);
}

__m128i test1_mm256_extracti128_si256_1(__m256i a) {
  return _mm256_extracti128_si256(a, 1);
}

// Immediate should be truncated to one bit.
__m128i test2_mm256_extracti128_si256(__m256i a) {
  return _mm256_extracti128_si256(a, 0);
}

__m256i test_mm256_hadd_epi16(__m256i a, __m256i b) {
  return _mm256_hadd_epi16(a, b);
}

__m256i test_mm256_hadd_epi32(__m256i a, __m256i b) {
  return _mm256_hadd_epi32(a, b);
}

__m256i test_mm256_hadds_epi16(__m256i a, __m256i b) {
  return _mm256_hadds_epi16(a, b);
}

__m256i test_mm256_hsub_epi16(__m256i a, __m256i b) {
  return _mm256_hsub_epi16(a, b);
}

__m256i test_mm256_hsub_epi32(__m256i a, __m256i b) {
  return _mm256_hsub_epi32(a, b);
}

__m256i test_mm256_hsubs_epi16(__m256i a, __m256i b) {
  return _mm256_hsubs_epi16(a, b);
}

__m128i test_mm_i32gather_epi32(int const *b, __m128i c) {
  return _mm_i32gather_epi32(b, c, 2);
}

__m128i test_mm_mask_i32gather_epi32(__m128i a, int const *b, __m128i c, __m128i d) {
  return _mm_mask_i32gather_epi32(a, b, c, d, 2);
}

__m256i test_mm256_i32gather_epi32(int const *b, __m256i c) {
  return _mm256_i32gather_epi32(b, c, 2);
}

__m256i test_mm256_mask_i32gather_epi32(__m256i a, int const *b, __m256i c, __m256i d) {
  return _mm256_mask_i32gather_epi32(a, b, c, d, 2);
}

__m128i test_mm_i32gather_epi64(long long const *b, __m128i c) {
  return _mm_i32gather_epi64(b, c, 2);
}

__m128i test_mm_mask_i32gather_epi64(__m128i a, long long const *b, __m128i c, __m128i d) {
  return _mm_mask_i32gather_epi64(a, b, c, d, 2);
}

__m256i test_mm256_i32gather_epi64(long long const *b, __m128i c) {
  //
  return _mm256_i32gather_epi64(b, c, 2);
}

__m256i test_mm256_mask_i32gather_epi64(__m256i a, long long const *b, __m128i c, __m256i d) {
  return _mm256_mask_i32gather_epi64(a, b, c, d, 2);
}

__m128d test_mm_i32gather_pd(double const *b, __m128i c) {
  //
  return _mm_i32gather_pd(b, c, 2);
}

__m128d test_mm_mask_i32gather_pd(__m128d a, double const *b, __m128i c, __m128d d) {
  return _mm_mask_i32gather_pd(a, b, c, d, 2);
}

__m256d test_mm256_i32gather_pd(double const *b, __m128i c) {
  //
  return _mm256_i32gather_pd(b, c, 2);
}

__m256d test_mm256_mask_i32gather_pd(__m256d a, double const *b, __m128i c, __m256d d) {
  return _mm256_mask_i32gather_pd(a, b, c, d, 2);
}

__m128 test_mm_i32gather_ps(float const *b, __m128i c) {
  //
  return _mm_i32gather_ps(b, c, 2);
}

__m128 test_mm_mask_i32gather_ps(__m128 a, float const *b, __m128i c, __m128 d) {
  return _mm_mask_i32gather_ps(a, b, c, d, 2);
}

__m256 test_mm256_i32gather_ps(float const *b, __m256i c) {
  //
  return _mm256_i32gather_ps(b, c, 2);
}

__m256 test_mm256_mask_i32gather_ps(__m256 a, float const *b, __m256i c, __m256 d) {
  return _mm256_mask_i32gather_ps(a, b, c, d, 2);
}

__m128i test_mm_i64gather_epi32(int const *b, __m128i c) {
  return _mm_i64gather_epi32(b, c, 2);
}

__m128i test_mm_mask_i64gather_epi32(__m128i a, int const *b, __m128i c, __m128i d) {
  return _mm_mask_i64gather_epi32(a, b, c, d, 2);
}

__m128i test_mm256_i64gather_epi32(int const *b, __m256i c) {
  return _mm256_i64gather_epi32(b, c, 2);
}

__m128i test_mm256_mask_i64gather_epi32(__m128i a, int const *b, __m256i c, __m128i d) {
  return _mm256_mask_i64gather_epi32(a, b, c, d, 2);
}

__m128i test_mm_i64gather_epi64(long long const *b, __m128i c) {
  return _mm_i64gather_epi64(b, c, 2);
}

__m128i test_mm_mask_i64gather_epi64(__m128i a, long long const *b, __m128i c, __m128i d) {
  return _mm_mask_i64gather_epi64(a, b, c, d, 2);
}

__m256i test_mm256_i64gather_epi64(long long const *b, __m256i c) {
  //
  return _mm256_i64gather_epi64(b, c, 2);
}

__m256i test_mm256_mask_i64gather_epi64(__m256i a, long long const *b, __m256i c, __m256i d) {
  return _mm256_mask_i64gather_epi64(a, b, c, d, 2);
}

__m128d test_mm_i64gather_pd(double const *b, __m128i c) {
  //
  return _mm_i64gather_pd(b, c, 2);
}

__m128d test_mm_mask_i64gather_pd(__m128d a, double const *b, __m128i c, __m128d d) {
  return _mm_mask_i64gather_pd(a, b, c, d, 2);
}

__m256d test_mm256_i64gather_pd(double const *b, __m256i c) {
  //
  return _mm256_i64gather_pd(b, c, 2);
}

__m256d test_mm256_mask_i64gather_pd(__m256d a, double const *b, __m256i c, __m256d d) {
  return _mm256_mask_i64gather_pd(a, b, c, d, 2);
}

__m128 test_mm_i64gather_ps(float const *b, __m128i c) {
  //
  return _mm_i64gather_ps(b, c, 2);
}

__m128 test_mm_mask_i64gather_ps(__m128 a, float const *b, __m128i c, __m128 d) {
  return _mm_mask_i64gather_ps(a, b, c, d, 2);
}

__m128 test_mm256_i64gather_ps(float const *b, __m256i c) {
  //
  return _mm256_i64gather_ps(b, c, 2);
}

__m128 test_mm256_mask_i64gather_ps(__m128 a, float const *b, __m256i c, __m128 d) {
  return _mm256_mask_i64gather_ps(a, b, c, d, 2);
}

__m256i test0_mm256_inserti128_si256(__m256i a, __m128i b) {
  return _mm256_inserti128_si256(a, b, 0);
}

__m256i test1_mm256_inserti128_si256(__m256i a, __m128i b) {
  return _mm256_inserti128_si256(a, b, 1);
}

// Immediate should be truncated to one bit.
__m256i test2_mm256_inserti128_si256(__m256i a, __m128i b) {
  return _mm256_inserti128_si256(a, b, 0);
}

__m256i test_mm256_madd_epi16(__m256i a, __m256i b) {
  return _mm256_madd_epi16(a, b);
}

__m256i test_mm256_maddubs_epi16(__m256i a, __m256i b) {
  return _mm256_maddubs_epi16(a, b);
}

__m128i test_mm_maskload_epi32(int const *a, __m128i m) {
  return _mm_maskload_epi32(a, m);
}

__m256i test_mm256_maskload_epi32(int const *a, __m256i m) {
  return _mm256_maskload_epi32(a, m);
}

__m128i test_mm_maskload_epi64(long long const *a, __m128i m) {
  return _mm_maskload_epi64(a, m);
}

__m256i test_mm256_maskload_epi64(long long const *a, __m256i m) {
  return _mm256_maskload_epi64(a, m);
}

void test_mm_maskstore_epi32(int *a, __m128i m, __m128i b) {
  _mm_maskstore_epi32(a, m, b);
}

void test_mm256_maskstore_epi32(int *a, __m256i m, __m256i b) {
  _mm256_maskstore_epi32(a, m, b);
}

void test_mm_maskstore_epi64(long long *a, __m128i m, __m128i b) {
  _mm_maskstore_epi64(a, m, b);
}

void test_mm256_maskstore_epi64(long long *a, __m256i m, __m256i b) {
  _mm256_maskstore_epi64(a, m, b);
}

__m256i test_mm256_max_epi8(__m256i a, __m256i b) {
  return _mm256_max_epi8(a, b);
}

__m256i test_mm256_max_epi16(__m256i a, __m256i b) {
  return _mm256_max_epi16(a, b);
}

__m256i test_mm256_max_epi32(__m256i a, __m256i b) {
  return _mm256_max_epi32(a, b);
}

__m256i test_mm256_max_epu8(__m256i a, __m256i b) {
  return _mm256_max_epu8(a, b);
}

__m256i test_mm256_max_epu16(__m256i a, __m256i b) {
  return _mm256_max_epu16(a, b);
}

__m256i test_mm256_max_epu32(__m256i a, __m256i b) {
  return _mm256_max_epu32(a, b);
}

__m256i test_mm256_min_epi8(__m256i a, __m256i b) {
  return _mm256_min_epi8(a, b);
}

__m256i test_mm256_min_epi16(__m256i a, __m256i b) {
  return _mm256_min_epi16(a, b);
}

__m256i test_mm256_min_epi32(__m256i a, __m256i b) {
  return _mm256_min_epi32(a, b);
}

__m256i test_mm256_min_epu8(__m256i a, __m256i b) {
  return _mm256_min_epu8(a, b);
}

__m256i test_mm256_min_epu16(__m256i a, __m256i b) {
  return _mm256_min_epu16(a, b);
}

__m256i test_mm256_min_epu32(__m256i a, __m256i b) {
  return _mm256_min_epu32(a, b);
}

int test_mm256_movemask_epi8(__m256i a) {
  return _mm256_movemask_epi8(a);
}

__m256i test_mm256_mpsadbw_epu8(__m256i x, __m256i y) {
  return _mm256_mpsadbw_epu8(x, y, 3);
}

__m256i test_mm256_mul_epi32(__m256i a, __m256i b) {
  return _mm256_mul_epi32(a, b);
}

__m256i test_mm256_mul_epu32(__m256i a, __m256i b) {
  return _mm256_mul_epu32(a, b);
}

__m256i test_mm256_mulhi_epu16(__m256i a, __m256i b) {
  return _mm256_mulhi_epu16(a, b);
}

__m256i test_mm256_mulhi_epi16(__m256i a, __m256i b) {
  return _mm256_mulhi_epi16(a, b);
}

__m256i test_mm256_mulhrs_epi16(__m256i a, __m256i b) {
  return _mm256_mulhrs_epi16(a, b);
}

__m256i test_mm256_mullo_epi16(__m256i a, __m256i b) {
  return _mm256_mullo_epi16(a, b);
}

__m256i test_mm256_mullo_epi32(__m256i a, __m256i b) {
  return _mm256_mullo_epi32(a, b);
}

__m256i test_mm256_or_si256(__m256i a, __m256i b) {
  return _mm256_or_si256(a, b);
}

__m256i test_mm256_packs_epi16(__m256i a, __m256i b) {
  return _mm256_packs_epi16(a, b);
}

__m256i test_mm256_packs_epi32(__m256i a, __m256i b) {
  return _mm256_packs_epi32(a, b);
}

__m256i test_mm256_packs_epu16(__m256i a, __m256i b) {
  return _mm256_packus_epi16(a, b);
}

__m256i test_mm256_packs_epu32(__m256i a, __m256i b) {
  return _mm256_packus_epi32(a, b);
}

__m256i test_mm256_permute2x128_si256(__m256i a, __m256i b) {
  return _mm256_permute2x128_si256(a, b, 0x38);
}

__m256i test_mm256_permute4x64_epi64(__m256i a) {
  return _mm256_permute4x64_epi64(a, 35);
}

__m256d test_mm256_permute4x64_pd(__m256d a) {
  return _mm256_permute4x64_pd(a, 25);
}

__m256i test_mm256_permutevar8x32_epi32(__m256i a, __m256i b) {
  return _mm256_permutevar8x32_epi32(a, b);
}

__m256 test_mm256_permutevar8x32_ps(__m256 a, __m256i b) {
  return _mm256_permutevar8x32_ps(a, b);
}

__m256i test_mm256_sad_epu8(__m256i x, __m256i y) {
  return _mm256_sad_epu8(x, y);
}

__m256i test_mm256_shuffle_epi8(__m256i a, __m256i b) {
  return _mm256_shuffle_epi8(a, b);
}

__m256i test_mm256_shuffle_epi32(__m256i a) {
  return _mm256_shuffle_epi32(a, 15);
}

__m256i test_mm256_shufflehi_epi16(__m256i a) {
  return _mm256_shufflehi_epi16(a, 107);
}

__m256i test_mm256_shufflelo_epi16(__m256i a) {
  return _mm256_shufflelo_epi16(a, 83);
}

__m256i test_mm256_sign_epi8(__m256i a, __m256i b) {
  return _mm256_sign_epi8(a, b);
}

__m256i test_mm256_sign_epi16(__m256i a, __m256i b) {
  return _mm256_sign_epi16(a, b);
}

__m256i test_mm256_sign_epi32(__m256i a, __m256i b) {
  return _mm256_sign_epi32(a, b);
}

__m256i test_mm256_slli_epi16(__m256i a) {
  return _mm256_slli_epi16(a, 3);
}

__m256i test_mm256_slli_epi16_2(__m256i a, int b) {
  return _mm256_slli_epi16(a, b);
}

__m256i test_mm256_slli_epi32(__m256i a) {
  return _mm256_slli_epi32(a, 3);
}

__m256i test_mm256_slli_epi32_2(__m256i a, int b) {
  return _mm256_slli_epi32(a, b);
}

__m256i test_mm256_slli_epi64(__m256i a) {
  return _mm256_slli_epi64(a, 3);
}

__m256i test_mm256_slli_epi64_2(__m256i a, int b) {
  return _mm256_slli_epi64(a, b);
}

__m256i test_mm256_slli_si256(__m256i a) {
  return _mm256_slli_si256(a, 3);
}

__m128i test_mm_sllv_epi32(__m128i a, __m128i b) {
  return _mm_sllv_epi32(a, b);
}

__m256i test_mm256_sllv_epi32(__m256i a, __m256i b) {
  return _mm256_sllv_epi32(a, b);
}

__m128i test_mm_sllv_epi64(__m128i a, __m128i b) {
  return _mm_sllv_epi64(a, b);
}

__m256i test_mm256_sllv_epi64(__m256i a, __m256i b) {
  return _mm256_sllv_epi64(a, b);
}

__m256i test_mm256_sra_epi16(__m256i a, __m128i b) {
  return _mm256_sra_epi16(a, b);
}

__m256i test_mm256_sra_epi32(__m256i a, __m128i b) {
  return _mm256_sra_epi32(a, b);
}

__m256i test_mm256_srai_epi16(__m256i a) {
  return _mm256_srai_epi16(a, 3);
}

__m256i test_mm256_srai_epi16_2(__m256i a, int b) {
  return _mm256_srai_epi16(a, b);
}

__m256i test_mm256_srai_epi32(__m256i a) {
  return _mm256_srai_epi32(a, 3);
}

__m256i test_mm256_srai_epi32_2(__m256i a, int b) {
  return _mm256_srai_epi32(a, b);
}

__m128i test_mm_srav_epi32(__m128i a, __m128i b) {
  return _mm_srav_epi32(a, b);
}

__m256i test_mm256_srav_epi32(__m256i a, __m256i b) {
  return _mm256_srav_epi32(a, b);
}

__m256i test_mm256_srl_epi16(__m256i a, __m128i b) {
  return _mm256_srl_epi16(a, b);
}

__m256i test_mm256_srl_epi32(__m256i a, __m128i b) {
  return _mm256_srl_epi32(a, b);
}

__m256i test_mm256_srl_epi64(__m256i a, __m128i b) {
  return _mm256_srl_epi64(a, b);
}

__m256i test_mm256_srli_epi16(__m256i a) {
  return _mm256_srli_epi16(a, 3);
}

__m256i test_mm256_srli_epi16_2(__m256i a, int b) {
  return _mm256_srli_epi16(a, b);
}

__m256i test_mm256_srli_epi32(__m256i a) {
  return _mm256_srli_epi32(a, 3);
}

__m256i test_mm256_srli_epi32_2(__m256i a, int b) {
  return _mm256_srli_epi32(a, b);
}

__m256i test_mm256_srli_epi64(__m256i a) {
  return _mm256_srli_epi64(a, 3);
}

__m256i test_mm256_srli_epi64_2(__m256i a, int b) {
  return _mm256_srli_epi64(a, b);
}

__m256i test_mm256_srli_si256(__m256i a) {
  return _mm256_srli_si256(a, 3);
}

__m128i test_mm_srlv_epi32(__m128i a, __m128i b) {
  return _mm_srlv_epi32(a, b);
}

__m256i test_mm256_srlv_epi32(__m256i a, __m256i b) {
  return _mm256_srlv_epi32(a, b);
}

__m128i test_mm_srlv_epi64(__m128i a, __m128i b) {
  return _mm_srlv_epi64(a, b);
}

__m256i test_mm256_srlv_epi64(__m256i a, __m256i b) {
  return _mm256_srlv_epi64(a, b);
}

__m256i test_mm256_stream_load_si256(__m256i const *a) {
  return _mm256_stream_load_si256(a);
}

__m256i test_mm256_stream_load_si256_void(const void *a) {
  return _mm256_stream_load_si256(a);
}

__m256i test_mm256_sub_epi8(__m256i a, __m256i b) {
  return _mm256_sub_epi8(a, b);
}

__m256i test_mm256_sub_epi16(__m256i a, __m256i b) {
  return _mm256_sub_epi16(a, b);
}

__m256i test_mm256_sub_epi32(__m256i a, __m256i b) {
  return _mm256_sub_epi32(a, b);
}

__m256i test_mm256_sub_epi64(__m256i a, __m256i b) {
  return _mm256_sub_epi64(a, b);
}

__m256i test_mm256_subs_epi8(__m256i a, __m256i b) {
  return _mm256_subs_epi8(a, b);
}

__m256i test_mm256_subs_epi16(__m256i a, __m256i b) {
  return _mm256_subs_epi16(a, b);
}

__m256i test_mm256_subs_epu8(__m256i a, __m256i b) {
  return _mm256_subs_epu8(a, b);
}

__m256i test_mm256_subs_epu16(__m256i a, __m256i b) {
  return _mm256_subs_epu16(a, b);
}

__m256i test_mm256_unpackhi_epi8(__m256i a, __m256i b) {
  return _mm256_unpackhi_epi8(a, b);
}

__m256i test_mm256_unpackhi_epi16(__m256i a, __m256i b) {
  return _mm256_unpackhi_epi16(a, b);
}

__m256i test_mm256_unpackhi_epi32(__m256i a, __m256i b) {
  return _mm256_unpackhi_epi32(a, b);
}

__m256i test_mm256_unpackhi_epi64(__m256i a, __m256i b) {
  return _mm256_unpackhi_epi64(a, b);
}

__m256i test_mm256_unpacklo_epi8(__m256i a, __m256i b) {
  return _mm256_unpacklo_epi8(a, b);
}

__m256i test_mm256_unpacklo_epi16(__m256i a, __m256i b) {
  return _mm256_unpacklo_epi16(a, b);
}

__m256i test_mm256_unpacklo_epi32(__m256i a, __m256i b) {
  return _mm256_unpacklo_epi32(a, b);
}

__m256i test_mm256_unpacklo_epi64(__m256i a, __m256i b) {
  return _mm256_unpacklo_epi64(a, b);
}

__m256i test_mm256_xor_si256(__m256i a, __m256i b) {
  return _mm256_xor_si256(a, b);
}
//// NOTE: These prefixes are unused and the list is autogenerated. Do not add tests below this line:
// CHECK: {{.*}}
// X64: {{.*}}
// X86: {{.*}}
