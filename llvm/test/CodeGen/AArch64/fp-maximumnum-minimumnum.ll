; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc --mtriple=aarch64 --mattr=+fullfp16 < %s | FileCheck %s --check-prefix=AARCH64

define <2 x double> @max_v2f64(<2 x double> %a, <2 x double> %b) {
; AARCH64-LABEL: max_v2f64:
; AARCH64:       // %bb.0: // %entry
; AARCH64-NEXT:    fmaxnm v0.2d, v0.2d, v1.2d
; AARCH64-NEXT:    ret
entry:
  %c = call nnan <2 x double> @llvm.maximumnum.v2f64(<2 x double> %a, <2 x double> %b)
  ret <2 x double> %c
}

define <4 x float> @max_v4f32(<4 x float> %a, <4 x float> %b) {
; AARCH64-LABEL: max_v4f32:
; AARCH64:       // %bb.0: // %entry
; AARCH64-NEXT:    fmaxnm v0.4s, v0.4s, v1.4s
; AARCH64-NEXT:    ret
entry:
  %c = call nnan <4 x float> @llvm.maximumnum.v2f64(<4 x float> %a, <4 x float> %b)
  ret <4 x float> %c
}


define <8 x half> @max_v8f16(<8 x half> %a, <8 x half> %b) {
; AARCH64-LABEL: max_v8f16:
; AARCH64:       // %bb.0: // %entry
; AARCH64-NEXT:    fmaxnm v0.8h, v0.8h, v1.8h
; AARCH64-NEXT:    ret
entry:
  %c = call nnan <8 x half> @llvm.maximumnum.v4f16(<8 x half> %a, <8 x half> %b)
  ret <8 x half> %c
}

define double @max_f64(double %a, double %b) {
; AARCH64-LABEL: max_f64:
; AARCH64:       // %bb.0: // %entry
; AARCH64-NEXT:    fmaxnm d0, d0, d1
; AARCH64-NEXT:    ret
entry:
  %c = call nnan double @llvm.maximumnum.f64(double %a, double %b)
  ret double %c
}

define float @max_f32(float %a, float %b) {
; AARCH64-LABEL: max_f32:
; AARCH64:       // %bb.0: // %entry
; AARCH64-NEXT:    fmaxnm s0, s0, s1
; AARCH64-NEXT:    ret
entry:
  %c = call nnan float @llvm.maximumnum.f32(float %a, float %b)
  ret float %c
}

define half @max_f16(half %a, half %b) {
; AARCH64-LABEL: max_f16:
; AARCH64:       // %bb.0: // %entry
; AARCH64-NEXT:    fmaxnm h0, h0, h1
; AARCH64-NEXT:    ret
entry:
  %c = call nnan half @llvm.maximumnum.f16(half %a, half %b)
  ret half %c
}

define <2 x double> @min_v2f64(<2 x double> %a, <2 x double> %b) {
; AARCH64-LABEL: min_v2f64:
; AARCH64:       // %bb.0: // %entry
; AARCH64-NEXT:    fminnm v0.2d, v0.2d, v1.2d
; AARCH64-NEXT:    ret
entry:
  %c = call nnan <2 x double> @llvm.minimumnum.v2f64(<2 x double> %a, <2 x double> %b)
  ret <2 x double> %c
}

define <4 x float> @min_v4f32(<4 x float> %a, <4 x float> %b) {
; AARCH64-LABEL: min_v4f32:
; AARCH64:       // %bb.0: // %entry
; AARCH64-NEXT:    fminnm v0.4s, v0.4s, v1.4s
; AARCH64-NEXT:    ret
entry:
  %c = call nnan <4 x float> @llvm.minimumnum.v2f64(<4 x float> %a, <4 x float> %b)
  ret <4 x float> %c
}


define <8 x half> @min_v8f16(<8 x half> %a, <8 x half> %b) {
; AARCH64-LABEL: min_v8f16:
; AARCH64:       // %bb.0: // %entry
; AARCH64-NEXT:    fminnm v0.8h, v0.8h, v1.8h
; AARCH64-NEXT:    ret
entry:
  %c = call nnan <8 x half> @llvm.minimumnum.v4f16(<8 x half> %a, <8 x half> %b)
  ret <8 x half> %c
}

define double @min_f64(double %a, double %b) {
; AARCH64-LABEL: min_f64:
; AARCH64:       // %bb.0: // %entry
; AARCH64-NEXT:    fminnm d0, d0, d1
; AARCH64-NEXT:    ret
entry:
  %c = call nnan double @llvm.minimumnum.f64(double %a, double %b)
  ret double %c
}

define float @min_f32(float %a, float %b) {
; AARCH64-LABEL: min_f32:
; AARCH64:       // %bb.0: // %entry
; AARCH64-NEXT:    fminnm s0, s0, s1
; AARCH64-NEXT:    ret
entry:
  %c = call nnan float @llvm.minimumnum.f32(float %a, float %b)
  ret float %c
}

define half @min_f16(half %a, half %b) {
; AARCH64-LABEL: min_f16:
; AARCH64:       // %bb.0: // %entry
; AARCH64-NEXT:    fminnm h0, h0, h1
; AARCH64-NEXT:    ret
entry:
  %c = call nnan half @llvm.minimumnum.f16(half %a, half %b)
  ret half %c
}

