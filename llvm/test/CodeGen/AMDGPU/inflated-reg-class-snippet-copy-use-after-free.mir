# RUN: not llc -mtriple=amdgcn-amd-amdhsa -mcpu=gfx90a -simplify-mir -start-before=greedy,2 -stress-regalloc=4 -stop-before=virtregrewriter,2 -o - -verify-regalloc %s 2> %t.err | FileCheck %s
# RUN: FileCheck -check-prefix=ERR %s < %t.err

# To allocate the vreg_512_align2, the allocation will attempt to
# inflate the register class to av_512_align2. This will ultimately
# not work, and the allocation will fail. Make sure we don't introduce
# an unproductive live range split of the inflated virtual register
# which will later hit a use after free.

# ERR: error: <unknown>:0:0: ran out of registers during register allocation in function 'inflated_reg_class_copy_use_after_free'

# CHECK: S_NOP 0, implicit-def %{{[0-9]+}}.sub0_sub1_sub2_sub3
# CHECK-NEXT: SI_SPILL_AV512_SAVE %{{[0-9]+}}, %stack.0, $sgpr32, 0, implicit $exec :: (store (s512) into %stack.0, align 4, addrspace 5)
# CHECK-NEXT: %{{[0-9]+}}:vreg_512_align2 = SI_SPILL_V512_RESTORE %stack.0, $sgpr32, 0, implicit $exec :: (load (s512) from %stack.0, align 4, addrspace 5)
# CHECK-NEXT: early-clobber %{{[0-9]+}}:vreg_512_align2 = V_MFMA_F32_16X16X1F32_vgprcd_e64 undef %3:vgpr_32, undef %3:vgpr_32, %{{[0-9]+}}, 0, 0, 0, implicit $mode, implicit $exec, implicit $mode, implicit $exec
# CHECK-NEXT: undef %{{[0-9]+}}.sub2_sub3:av_512_align2 = COPY %{{[0-9]+}}.sub2_sub3 {
# CHECK-NEXT: internal %{{[0-9]+}}.sub0:av_512_align2 = COPY %{{[0-9]+}}.sub0
# CHECK-NEXT: }
# CHECK-NEXT: undef %{{[0-9]+}}.sub2_sub3:av_512_align2 = COPY %{{[0-9]+}}.sub2_sub3 {
# CHECK-NEXT: internal %{{[0-9]+}}.sub0:av_512_align2 = COPY %{{[0-9]+}}.sub0
# CHECK-NEXT: }
# CHECK-NEXT: undef %{{[0-9]+}}.sub2_sub3:av_512_align2 = COPY %{{[0-9]+}}.sub2_sub3 {
# CHECK-NEXT: internal %{{[0-9]+}}.sub0:av_512_align2 = COPY %{{[0-9]+}}.sub0
# CHECK-NEXT: }
# CHECK-NEXT: undef %27.sub2_sub3:av_512_align2 = COPY %{{[0-9]+}}.sub2_sub3 {
# CHECK-NEXT: internal %27.sub0:av_512_align2 = COPY %{{[0-9]+}}.sub0
# CHECK-NEXT: }
# CHECK-NEXT: SI_SPILL_AV512_SAVE %27, %stack.1, $sgpr32, 0, implicit $exec :: (store (s512) into %stack.1, align 4, addrspace 5)
# CHECK-NEXT: %16:vreg_512_align2 = SI_SPILL_V512_RESTORE %stack.0, $sgpr32, 0, implicit $exec :: (load (s512) from %stack.0, align 4, addrspace 5)
# CHECK-NEXT: undef %{{[0-9]+}}.sub0_sub1:av_512_align2 = COPY %16.sub0_sub1
# CHECK-NEXT: %28:av_512_align2 = SI_SPILL_AV512_RESTORE %stack.1, $sgpr32, 0, implicit $exec :: (load (s512) from %stack.1, align 4, addrspace 5)
# CHECK-NEXT: undef %{{[0-9]+}}.sub2_sub3:av_512_align2 = COPY %28.sub2_sub3 {
# CHECK-NEXT: internal %{{[0-9]+}}.sub0:av_512_align2 = COPY %28.sub0
# CHECK-NEXT: }
# CHECK-NEXT: undef %{{[0-9]+}}.sub2_sub3:av_512_align2 = COPY %{{[0-9]+}}.sub2_sub3 {
# CHECK-NEXT: internal %{{[0-9]+}}.sub0:av_512_align2 = COPY %{{[0-9]+}}.sub0
# CHECK-NEXT: }
# CHECK-NEXT: %{{[0-9]+}}.sub2:av_512_align2 = COPY %{{[0-9]+}}.sub3
# CHECK-NEXT: undef %{{[0-9]+}}.sub0_sub1_sub2:av_512_align2 = COPY %{{[0-9]+}}.sub0_sub1_sub2
# CHECK-NEXT: undef %{{[0-9]+}}.sub0_sub1_sub2:av_512_align2 = COPY %{{[0-9]+}}.sub0_sub1_sub2
# CHECK-NEXT: undef %{{[0-9]+}}.sub0:av_512_align2 = COPY %{{[0-9]+}}.sub0 {
# CHECK-NEXT: internal %{{[0-9]+}}.sub2:av_512_align2 = COPY %{{[0-9]+}}.sub2
# CHECK-NEXT: }
# CHECK-NEXT: %{{[0-9]+}}.sub3:av_512_align2 = COPY %{{[0-9]+}}.sub2
# CHECK-NEXT: undef %14.sub0_sub1_sub2_sub3:av_512_align2 = COPY %{{[0-9]+}}.sub0_sub1_sub2_sub3
# CHECK-NEXT: undef %7.sub0_sub1_sub2_sub3:vreg_512_align2 = COPY %14.sub0_sub1_sub2_sub3
# CHECK-NEXT: %7.sub4:vreg_512_align2 = COPY %{{[0-9]+}}.sub0
# CHECK-NEXT: %{{[0-9]+}}.sub5:vreg_512_align2 = V_MOV_B32_e32 0, implicit $exec
# CHECK-NEXT: %{{[0-9]+}}.sub6:vreg_512_align2 = V_MOV_B32_e32 0, implicit $exec
# CHECK-NEXT: %{{[0-9]+}}.sub7:vreg_512_align2 = V_MOV_B32_e32 0, implicit $exec
# CHECK-NEXT: %{{[0-9]+}}.sub8:vreg_512_align2 = V_MOV_B32_e32 0, implicit $exec
# CHECK-NEXT: %{{[0-9]+}}.sub9:vreg_512_align2 = V_MOV_B32_e32 0, implicit $exec
# CHECK-NEXT: %{{[0-9]+}}.sub10:vreg_512_align2 = V_MOV_B32_e32 0, implicit $exec
# CHECK-NEXT: %{{[0-9]+}}.sub11:vreg_512_align2 = V_MOV_B32_e32 0, implicit $exec
# CHECK-NEXT: %{{[0-9]+}}.sub12:vreg_512_align2 = V_MOV_B32_e32 0, implicit $exec
# CHECK-NEXT: %{{[0-9]+}}.sub13:vreg_512_align2 = V_MOV_B32_e32 0, implicit $exec
# CHECK-NEXT: %{{[0-9]+}}.sub14:vreg_512_align2 = V_MOV_B32_e32 0, implicit $exec
# CHECK-NEXT: %{{[0-9]+}}.sub15:vreg_512_align2 = V_MOV_B32_e32 0, implicit $exec
# CHECK-NEXT: %{{[0-9]+}}:vreg_512_align2 = V_MFMA_F32_16X16X1F32_mac_vgprcd_e64 undef %3:vgpr_32, undef %3:vgpr_32, %{{[0-9]+}}, 0, 0, 0, implicit $mode, implicit $exec

--- |
  define amdgpu_kernel void @inflated_reg_class_copy_use_after_free() {
    ret void
  }
...
---
name:            inflated_reg_class_copy_use_after_free
tracksRegLiveness: true
machineFunctionInfo:
  explicitKernArgSize: 8
  maxKernArgAlign: 8
  isEntryFunction: true
  memoryBound:     true
  waveLimiter:     true
  scratchRSrcReg:  '$sgpr72_sgpr73_sgpr74_sgpr75'
  stackPtrOffsetReg: '$sgpr32'
  returnsVoid:     true
  occupancy:       7
  vgprForAGPRCopy: '$vgpr255'
  sgprForEXECCopy: '$sgpr74_sgpr75'
  longBranchReservedReg: ''
body:             |
  bb.0:
    liveins: $vgpr0, $sgpr4_sgpr5

    %0:vgpr_32 = IMPLICIT_DEF
    renamable $sgpr0_sgpr1 = S_LOAD_DWORDX2_IMM killed undef renamable $sgpr4_sgpr5, 0, 0 :: (load (s64), addrspace 4)
    S_NOP 0, implicit-def undef %1.sub12_sub13_sub14_sub15:vreg_512_align2
    S_NOP 0, implicit-def %1.sub8_sub9_sub10_sub11:vreg_512_align2
    S_NOP 0, implicit-def %1.sub4_sub5_sub6_sub7:vreg_512_align2
    S_NOP 0, implicit-def %1.sub0_sub1_sub2_sub3:vreg_512_align2
    early-clobber %2:vreg_512_align2 = V_MFMA_F32_16X16X1F32_vgprcd_e64 undef %3:vgpr_32, undef %3:vgpr_32, %1, 0, 0, 0, implicit $mode, implicit $exec, implicit $mode, implicit $exec
    %1.sub2:vreg_512_align2 = COPY %2.sub3
    %1.sub3:vreg_512_align2 = COPY %2.sub2
    %1.sub4:vreg_512_align2 = COPY %2.sub0
    %1.sub5:vreg_512_align2 = V_MOV_B32_e32 0, implicit $exec
    %1.sub6:vreg_512_align2 = V_MOV_B32_e32 0, implicit $exec
    %1.sub7:vreg_512_align2 = V_MOV_B32_e32 0, implicit $exec
    %1.sub8:vreg_512_align2 = V_MOV_B32_e32 0, implicit $exec
    %1.sub9:vreg_512_align2 = V_MOV_B32_e32 0, implicit $exec
    %1.sub10:vreg_512_align2 = V_MOV_B32_e32 0, implicit $exec
    %1.sub11:vreg_512_align2 = V_MOV_B32_e32 0, implicit $exec
    %1.sub12:vreg_512_align2 = V_MOV_B32_e32 0, implicit $exec
    %1.sub13:vreg_512_align2 = V_MOV_B32_e32 0, implicit $exec
    %1.sub14:vreg_512_align2 = V_MOV_B32_e32 0, implicit $exec
    %1.sub15:vreg_512_align2 = V_MOV_B32_e32 0, implicit $exec
    %1:vreg_512_align2 = V_MFMA_F32_16X16X1F32_mac_vgprcd_e64 undef %3:vgpr_32, undef %3:vgpr_32, %1, 0, 0, 0, implicit $mode, implicit $exec
    GLOBAL_STORE_DWORDX4_SADDR undef %3:vgpr_32, %1.sub12_sub13_sub14_sub15, undef renamable $sgpr0_sgpr1, 96, 0, implicit $exec :: (store (s128), addrspace 1)
    S_ENDPGM 0

...
