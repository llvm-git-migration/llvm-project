; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 3
; RUN: opt -passes='infer-alignment' -mtriple=amdgcn -mcpu=gfx90a -S < %s  | FileCheck -check-prefix=AMDGPU %s
; RUN: opt -passes='infer-alignment' -mcpu=corei7 -mtriple=x86_64-linux -S < %s  | FileCheck -check-prefix=X86 %s

$globalArrayAS0 = comdat any
$globalArrayAS256 = comdat any
$globalArrayAS257 = comdat any
$globalArrayAS258 = comdat any
$globalArrayAS270 = comdat any
$globalArrayAS271 = comdat any
$globalArrayAS272 = comdat any
@globalArrayAS0 = linkonce_odr hidden addrspace(0) global [4096 x i8] undef, comdat, align 16
@globalArrayAS256 = linkonce_odr hidden addrspace(256) global [4096 x i8] undef, comdat, align 16
@globalArrayAS257 = linkonce_odr hidden addrspace(257) global [4096 x i8] undef, comdat, align 16
@globalArrayAS258 = linkonce_odr hidden addrspace(258) global [4096 x i8] undef, comdat, align 16
@globalArrayAS270 = linkonce_odr hidden addrspace(270) global [4096 x i8] undef, comdat, align 16
@globalArrayAS271 = linkonce_odr hidden addrspace(271) global [4096 x i8] undef, comdat, align 16
@globalArrayAS272 = linkonce_odr hidden addrspace(272) global [4096 x i8] undef, comdat, align 16

; Function Attrs: alwaysinline convergent mustprogress nounwind
define amdgpu_kernel void @infer_AS10(i32 %idx) unnamed_addr align 2 {
; AMDGPU-LABEL: define amdgpu_kernel void @infer_AS10(
; AMDGPU-SAME: i32 [[IDX:%.*]]) unnamed_addr #[[ATTR0:[0-9]+]] align 2 {
; AMDGPU-NEXT:  entry:
; AMDGPU-NEXT:    [[MUL32_I:%.*]] = shl nuw nsw i32 [[IDX]], 8
; AMDGPU-NEXT:    [[ADD36_I:%.*]] = add nuw nsw i32 [[MUL32_I]], 1024
; AMDGPU-NEXT:    [[IDXPROM37_I21:%.*]] = zext i32 [[ADD36_I]] to i64
; AMDGPU-NEXT:    [[ARRAYIDX38_I22:%.*]] = getelementptr inbounds float, ptr addrspacecast (ptr addrspace(256) @globalArrayAS256 to ptr), i64 [[IDXPROM37_I21]]
; AMDGPU-NEXT:    [[L1:%.*]] = load float, ptr [[ARRAYIDX38_I22]], align 16
; AMDGPU-NEXT:    ret void
;
; X86-LABEL: define amdgpu_kernel void @infer_AS10(
; X86-SAME: i32 [[IDX:%.*]]) unnamed_addr #[[ATTR0:[0-9]+]] align 2 {
; X86-NEXT:  entry:
; X86-NEXT:    [[MUL32_I:%.*]] = shl nuw nsw i32 [[IDX]], 8
; X86-NEXT:    [[ADD36_I:%.*]] = add nuw nsw i32 [[MUL32_I]], 1024
; X86-NEXT:    [[IDXPROM37_I21:%.*]] = zext i32 [[ADD36_I]] to i64
; X86-NEXT:    [[ARRAYIDX38_I22:%.*]] = getelementptr inbounds float, ptr addrspacecast (ptr addrspace(256) @globalArrayAS256 to ptr), i64 [[IDXPROM37_I21]]
; X86-NEXT:    [[L1:%.*]] = load float, ptr [[ARRAYIDX38_I22]], align 16
; X86-NEXT:    ret void
;
entry:
  %mul32.i = shl nuw nsw i32 %idx, 8
  %add36.i = add nuw nsw i32 %mul32.i, 1024
  %idxprom37.i21 = zext i32 %add36.i to i64
  %arrayidx38.i22 = getelementptr inbounds float, ptr addrspacecast (ptr addrspace(256) @globalArrayAS256 to ptr), i64 %idxprom37.i21
  %l1 = load float, ptr  %arrayidx38.i22, align 4
  ret void
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define amdgpu_kernel void @infer_AS20(i32 %idx) unnamed_addr align 2 {
; AMDGPU-LABEL: define amdgpu_kernel void @infer_AS20(
; AMDGPU-SAME: i32 [[IDX:%.*]]) unnamed_addr #[[ATTR0]] align 2 {
; AMDGPU-NEXT:  entry:
; AMDGPU-NEXT:    [[MUL32_I:%.*]] = shl nuw nsw i32 [[IDX]], 8
; AMDGPU-NEXT:    [[ADD36_I:%.*]] = add nuw nsw i32 [[MUL32_I]], 1024
; AMDGPU-NEXT:    [[IDXPROM37_I21:%.*]] = zext i32 [[ADD36_I]] to i64
; AMDGPU-NEXT:    [[ARRAYIDX38_I22:%.*]] = getelementptr inbounds float, ptr addrspacecast (ptr addrspace(257) @globalArrayAS257 to ptr), i64 [[IDXPROM37_I21]]
; AMDGPU-NEXT:    [[L1:%.*]] = load float, ptr [[ARRAYIDX38_I22]], align 16
; AMDGPU-NEXT:    ret void
;
; X86-LABEL: define amdgpu_kernel void @infer_AS20(
; X86-SAME: i32 [[IDX:%.*]]) unnamed_addr #[[ATTR0]] align 2 {
; X86-NEXT:  entry:
; X86-NEXT:    [[MUL32_I:%.*]] = shl nuw nsw i32 [[IDX]], 8
; X86-NEXT:    [[ADD36_I:%.*]] = add nuw nsw i32 [[MUL32_I]], 1024
; X86-NEXT:    [[IDXPROM37_I21:%.*]] = zext i32 [[ADD36_I]] to i64
; X86-NEXT:    [[ARRAYIDX38_I22:%.*]] = getelementptr inbounds float, ptr addrspacecast (ptr addrspace(257) @globalArrayAS257 to ptr), i64 [[IDXPROM37_I21]]
; X86-NEXT:    [[L1:%.*]] = load float, ptr [[ARRAYIDX38_I22]], align 16
; X86-NEXT:    ret void
;
entry:
  %mul32.i = shl nuw nsw i32 %idx, 8
  %add36.i = add nuw nsw i32 %mul32.i, 1024
  %idxprom37.i21 = zext i32 %add36.i to i64
  %arrayidx38.i22 = getelementptr inbounds float, ptr addrspacecast (ptr addrspace(257) @globalArrayAS257 to ptr), i64 %idxprom37.i21
  %l1 = load float, ptr  %arrayidx38.i22, align 4
  ret void
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define amdgpu_kernel void @infer_AS30(i32 %idx) unnamed_addr align 2 {
; AMDGPU-LABEL: define amdgpu_kernel void @infer_AS30(
; AMDGPU-SAME: i32 [[IDX:%.*]]) unnamed_addr #[[ATTR0]] align 2 {
; AMDGPU-NEXT:  entry:
; AMDGPU-NEXT:    [[MUL32_I:%.*]] = shl nuw nsw i32 [[IDX]], 8
; AMDGPU-NEXT:    [[ADD36_I:%.*]] = add nuw nsw i32 [[MUL32_I]], 1024
; AMDGPU-NEXT:    [[IDXPROM37_I21:%.*]] = zext i32 [[ADD36_I]] to i64
; AMDGPU-NEXT:    [[ARRAYIDX38_I22:%.*]] = getelementptr inbounds float, ptr addrspacecast (ptr addrspace(258) @globalArrayAS258 to ptr), i64 [[IDXPROM37_I21]]
; AMDGPU-NEXT:    [[L1:%.*]] = load float, ptr [[ARRAYIDX38_I22]], align 16
; AMDGPU-NEXT:    ret void
;
; X86-LABEL: define amdgpu_kernel void @infer_AS30(
; X86-SAME: i32 [[IDX:%.*]]) unnamed_addr #[[ATTR0]] align 2 {
; X86-NEXT:  entry:
; X86-NEXT:    [[MUL32_I:%.*]] = shl nuw nsw i32 [[IDX]], 8
; X86-NEXT:    [[ADD36_I:%.*]] = add nuw nsw i32 [[MUL32_I]], 1024
; X86-NEXT:    [[IDXPROM37_I21:%.*]] = zext i32 [[ADD36_I]] to i64
; X86-NEXT:    [[ARRAYIDX38_I22:%.*]] = getelementptr inbounds float, ptr addrspacecast (ptr addrspace(258) @globalArrayAS258 to ptr), i64 [[IDXPROM37_I21]]
; X86-NEXT:    [[L1:%.*]] = load float, ptr [[ARRAYIDX38_I22]], align 16
; X86-NEXT:    ret void
;
entry:
  %mul32.i = shl nuw nsw i32 %idx, 8
  %add36.i = add nuw nsw i32 %mul32.i, 1024
  %idxprom37.i21 = zext i32 %add36.i to i64
  %arrayidx38.i22 = getelementptr inbounds float, ptr addrspacecast (ptr addrspace(258) @globalArrayAS258 to ptr), i64 %idxprom37.i21
  %l1 = load float, ptr  %arrayidx38.i22, align 4
  ret void
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define amdgpu_kernel void @infer_AS40(i32 %idx) unnamed_addr align 2 {
; AMDGPU-LABEL: define amdgpu_kernel void @infer_AS40(
; AMDGPU-SAME: i32 [[IDX:%.*]]) unnamed_addr #[[ATTR0]] align 2 {
; AMDGPU-NEXT:  entry:
; AMDGPU-NEXT:    [[MUL32_I:%.*]] = shl nuw nsw i32 [[IDX]], 8
; AMDGPU-NEXT:    [[ADD36_I:%.*]] = add nuw nsw i32 [[MUL32_I]], 1024
; AMDGPU-NEXT:    [[IDXPROM37_I21:%.*]] = zext i32 [[ADD36_I]] to i64
; AMDGPU-NEXT:    [[ARRAYIDX38_I22:%.*]] = getelementptr inbounds float, ptr addrspacecast (ptr addrspace(270) @globalArrayAS270 to ptr), i64 [[IDXPROM37_I21]]
; AMDGPU-NEXT:    [[L1:%.*]] = load float, ptr [[ARRAYIDX38_I22]], align 16
; AMDGPU-NEXT:    ret void
;
; X86-LABEL: define amdgpu_kernel void @infer_AS40(
; X86-SAME: i32 [[IDX:%.*]]) unnamed_addr #[[ATTR0]] align 2 {
; X86-NEXT:  entry:
; X86-NEXT:    [[MUL32_I:%.*]] = shl nuw nsw i32 [[IDX]], 8
; X86-NEXT:    [[ADD36_I:%.*]] = add nuw nsw i32 [[MUL32_I]], 1024
; X86-NEXT:    [[IDXPROM37_I21:%.*]] = zext i32 [[ADD36_I]] to i64
; X86-NEXT:    [[ARRAYIDX38_I22:%.*]] = getelementptr inbounds float, ptr addrspacecast (ptr addrspace(270) @globalArrayAS270 to ptr), i64 [[IDXPROM37_I21]]
; X86-NEXT:    [[L1:%.*]] = load float, ptr [[ARRAYIDX38_I22]], align 16
; X86-NEXT:    ret void
;
entry:
  %mul32.i = shl nuw nsw i32 %idx, 8
  %add36.i = add nuw nsw i32 %mul32.i, 1024
  %idxprom37.i21 = zext i32 %add36.i to i64
  %arrayidx38.i22 = getelementptr inbounds float, ptr addrspacecast (ptr addrspace(270) @globalArrayAS270 to ptr), i64 %idxprom37.i21
  %l1 = load float, ptr  %arrayidx38.i22, align 4
  ret void
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define amdgpu_kernel void @infer_AS50(i32 %idx) unnamed_addr align 2 {
; AMDGPU-LABEL: define amdgpu_kernel void @infer_AS50(
; AMDGPU-SAME: i32 [[IDX:%.*]]) unnamed_addr #[[ATTR0]] align 2 {
; AMDGPU-NEXT:  entry:
; AMDGPU-NEXT:    [[MUL32_I:%.*]] = shl nuw nsw i32 [[IDX]], 8
; AMDGPU-NEXT:    [[ADD36_I:%.*]] = add nuw nsw i32 [[MUL32_I]], 1024
; AMDGPU-NEXT:    [[IDXPROM37_I21:%.*]] = zext i32 [[ADD36_I]] to i64
; AMDGPU-NEXT:    [[ARRAYIDX38_I22:%.*]] = getelementptr inbounds float, ptr addrspacecast (ptr addrspace(271) @globalArrayAS271 to ptr), i64 [[IDXPROM37_I21]]
; AMDGPU-NEXT:    [[L1:%.*]] = load float, ptr [[ARRAYIDX38_I22]], align 16
; AMDGPU-NEXT:    ret void
;
; X86-LABEL: define amdgpu_kernel void @infer_AS50(
; X86-SAME: i32 [[IDX:%.*]]) unnamed_addr #[[ATTR0]] align 2 {
; X86-NEXT:  entry:
; X86-NEXT:    [[MUL32_I:%.*]] = shl nuw nsw i32 [[IDX]], 8
; X86-NEXT:    [[ADD36_I:%.*]] = add nuw nsw i32 [[MUL32_I]], 1024
; X86-NEXT:    [[IDXPROM37_I21:%.*]] = zext i32 [[ADD36_I]] to i64
; X86-NEXT:    [[ARRAYIDX38_I22:%.*]] = getelementptr inbounds float, ptr addrspacecast (ptr addrspace(271) @globalArrayAS271 to ptr), i64 [[IDXPROM37_I21]]
; X86-NEXT:    [[L1:%.*]] = load float, ptr [[ARRAYIDX38_I22]], align 16
; X86-NEXT:    ret void
;
entry:
  %mul32.i = shl nuw nsw i32 %idx, 8
  %add36.i = add nuw nsw i32 %mul32.i, 1024
  %idxprom37.i21 = zext i32 %add36.i to i64
  %arrayidx38.i22 = getelementptr inbounds float, ptr addrspacecast (ptr addrspace(271) @globalArrayAS271 to ptr), i64 %idxprom37.i21
  %l1 = load float, ptr  %arrayidx38.i22, align 4
  ret void
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define amdgpu_kernel void @infer_AS60(i32 %idx) unnamed_addr align 2 {
; AMDGPU-LABEL: define amdgpu_kernel void @infer_AS60(
; AMDGPU-SAME: i32 [[IDX:%.*]]) unnamed_addr #[[ATTR0]] align 2 {
; AMDGPU-NEXT:  entry:
; AMDGPU-NEXT:    [[MUL32_I:%.*]] = shl nuw nsw i32 [[IDX]], 8
; AMDGPU-NEXT:    [[ADD36_I:%.*]] = add nuw nsw i32 [[MUL32_I]], 1024
; AMDGPU-NEXT:    [[IDXPROM37_I21:%.*]] = zext i32 [[ADD36_I]] to i64
; AMDGPU-NEXT:    [[ARRAYIDX38_I22:%.*]] = getelementptr inbounds float, ptr addrspacecast (ptr addrspace(272) @globalArrayAS272 to ptr), i64 [[IDXPROM37_I21]]
; AMDGPU-NEXT:    [[L1:%.*]] = load float, ptr [[ARRAYIDX38_I22]], align 16
; AMDGPU-NEXT:    ret void
;
; X86-LABEL: define amdgpu_kernel void @infer_AS60(
; X86-SAME: i32 [[IDX:%.*]]) unnamed_addr #[[ATTR0]] align 2 {
; X86-NEXT:  entry:
; X86-NEXT:    [[MUL32_I:%.*]] = shl nuw nsw i32 [[IDX]], 8
; X86-NEXT:    [[ADD36_I:%.*]] = add nuw nsw i32 [[MUL32_I]], 1024
; X86-NEXT:    [[IDXPROM37_I21:%.*]] = zext i32 [[ADD36_I]] to i64
; X86-NEXT:    [[ARRAYIDX38_I22:%.*]] = getelementptr inbounds float, ptr addrspacecast (ptr addrspace(272) @globalArrayAS272 to ptr), i64 [[IDXPROM37_I21]]
; X86-NEXT:    [[L1:%.*]] = load float, ptr [[ARRAYIDX38_I22]], align 16
; X86-NEXT:    ret void
;
entry:
  %mul32.i = shl nuw nsw i32 %idx, 8
  %add36.i = add nuw nsw i32 %mul32.i, 1024
  %idxprom37.i21 = zext i32 %add36.i to i64
  %arrayidx38.i22 = getelementptr inbounds float, ptr addrspacecast (ptr addrspace(272) @globalArrayAS272 to ptr), i64 %idxprom37.i21
  %l1 = load float, ptr  %arrayidx38.i22, align 4
  ret void
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define amdgpu_kernel void @infer_AS01(i32 %idx) unnamed_addr align 2 {
; AMDGPU-LABEL: define amdgpu_kernel void @infer_AS01(
; AMDGPU-SAME: i32 [[IDX:%.*]]) unnamed_addr #[[ATTR0]] align 2 {
; AMDGPU-NEXT:  entry:
; AMDGPU-NEXT:    [[MUL32_I:%.*]] = shl nuw nsw i32 [[IDX]], 8
; AMDGPU-NEXT:    [[ADD36_I:%.*]] = add nuw nsw i32 [[MUL32_I]], 1024
; AMDGPU-NEXT:    [[IDXPROM37_I21:%.*]] = zext i32 [[ADD36_I]] to i64
; AMDGPU-NEXT:    [[ARRAYIDX38_I22:%.*]] = getelementptr inbounds float, ptr addrspace(256) addrspacecast (ptr @globalArrayAS0 to ptr addrspace(256)), i64 [[IDXPROM37_I21]]
; AMDGPU-NEXT:    [[L1:%.*]] = load float, ptr addrspace(256) [[ARRAYIDX38_I22]], align 16
; AMDGPU-NEXT:    ret void
;
; X86-LABEL: define amdgpu_kernel void @infer_AS01(
; X86-SAME: i32 [[IDX:%.*]]) unnamed_addr #[[ATTR0]] align 2 {
; X86-NEXT:  entry:
; X86-NEXT:    [[MUL32_I:%.*]] = shl nuw nsw i32 [[IDX]], 8
; X86-NEXT:    [[ADD36_I:%.*]] = add nuw nsw i32 [[MUL32_I]], 1024
; X86-NEXT:    [[IDXPROM37_I21:%.*]] = zext i32 [[ADD36_I]] to i64
; X86-NEXT:    [[ARRAYIDX38_I22:%.*]] = getelementptr inbounds float, ptr addrspace(256) addrspacecast (ptr @globalArrayAS0 to ptr addrspace(256)), i64 [[IDXPROM37_I21]]
; X86-NEXT:    [[L1:%.*]] = load float, ptr addrspace(256) [[ARRAYIDX38_I22]], align 16
; X86-NEXT:    ret void
;
entry:
  %mul32.i = shl nuw nsw i32 %idx, 8
  %add36.i = add nuw nsw i32 %mul32.i, 1024
  %idxprom37.i21 = zext i32 %add36.i to i64
  %arrayidx38.i22 = getelementptr inbounds float, ptr addrspace(256) addrspacecast (ptr @globalArrayAS0 to ptr addrspace(256)), i64 %idxprom37.i21
  %l1 = load float, ptr addrspace(256) %arrayidx38.i22, align 4
  ret void
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define amdgpu_kernel void @infer_AS02(i32 %idx) unnamed_addr align 2 {
; AMDGPU-LABEL: define amdgpu_kernel void @infer_AS02(
; AMDGPU-SAME: i32 [[IDX:%.*]]) unnamed_addr #[[ATTR0]] align 2 {
; AMDGPU-NEXT:  entry:
; AMDGPU-NEXT:    [[MUL32_I:%.*]] = shl nuw nsw i32 [[IDX]], 8
; AMDGPU-NEXT:    [[ADD36_I:%.*]] = add nuw nsw i32 [[MUL32_I]], 1024
; AMDGPU-NEXT:    [[IDXPROM37_I21:%.*]] = zext i32 [[ADD36_I]] to i64
; AMDGPU-NEXT:    [[ARRAYIDX38_I22:%.*]] = getelementptr inbounds float, ptr addrspace(257) addrspacecast (ptr @globalArrayAS0 to ptr addrspace(257)), i64 [[IDXPROM37_I21]]
; AMDGPU-NEXT:    [[L1:%.*]] = load float, ptr addrspace(257) [[ARRAYIDX38_I22]], align 16
; AMDGPU-NEXT:    ret void
;
; X86-LABEL: define amdgpu_kernel void @infer_AS02(
; X86-SAME: i32 [[IDX:%.*]]) unnamed_addr #[[ATTR0]] align 2 {
; X86-NEXT:  entry:
; X86-NEXT:    [[MUL32_I:%.*]] = shl nuw nsw i32 [[IDX]], 8
; X86-NEXT:    [[ADD36_I:%.*]] = add nuw nsw i32 [[MUL32_I]], 1024
; X86-NEXT:    [[IDXPROM37_I21:%.*]] = zext i32 [[ADD36_I]] to i64
; X86-NEXT:    [[ARRAYIDX38_I22:%.*]] = getelementptr inbounds float, ptr addrspace(257) addrspacecast (ptr @globalArrayAS0 to ptr addrspace(257)), i64 [[IDXPROM37_I21]]
; X86-NEXT:    [[L1:%.*]] = load float, ptr addrspace(257) [[ARRAYIDX38_I22]], align 16
; X86-NEXT:    ret void
;
entry:
  %mul32.i = shl nuw nsw i32 %idx, 8
  %add36.i = add nuw nsw i32 %mul32.i, 1024
  %idxprom37.i21 = zext i32 %add36.i to i64
  %arrayidx38.i22 = getelementptr inbounds float, ptr addrspace(257) addrspacecast (ptr @globalArrayAS0 to ptr addrspace(257)), i64 %idxprom37.i21
  %l1 = load float, ptr addrspace(257) %arrayidx38.i22, align 4
  ret void
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define amdgpu_kernel void @infer_AS03(i32 %idx) unnamed_addr align 2 {
; AMDGPU-LABEL: define amdgpu_kernel void @infer_AS03(
; AMDGPU-SAME: i32 [[IDX:%.*]]) unnamed_addr #[[ATTR0]] align 2 {
; AMDGPU-NEXT:  entry:
; AMDGPU-NEXT:    [[MUL32_I:%.*]] = shl nuw nsw i32 [[IDX]], 8
; AMDGPU-NEXT:    [[ADD36_I:%.*]] = add nuw nsw i32 [[MUL32_I]], 1024
; AMDGPU-NEXT:    [[IDXPROM37_I21:%.*]] = zext i32 [[ADD36_I]] to i64
; AMDGPU-NEXT:    [[ARRAYIDX38_I22:%.*]] = getelementptr inbounds float, ptr addrspace(258) addrspacecast (ptr @globalArrayAS0 to ptr addrspace(258)), i64 [[IDXPROM37_I21]]
; AMDGPU-NEXT:    [[L1:%.*]] = load float, ptr addrspace(258) [[ARRAYIDX38_I22]], align 16
; AMDGPU-NEXT:    ret void
;
; X86-LABEL: define amdgpu_kernel void @infer_AS03(
; X86-SAME: i32 [[IDX:%.*]]) unnamed_addr #[[ATTR0]] align 2 {
; X86-NEXT:  entry:
; X86-NEXT:    [[MUL32_I:%.*]] = shl nuw nsw i32 [[IDX]], 8
; X86-NEXT:    [[ADD36_I:%.*]] = add nuw nsw i32 [[MUL32_I]], 1024
; X86-NEXT:    [[IDXPROM37_I21:%.*]] = zext i32 [[ADD36_I]] to i64
; X86-NEXT:    [[ARRAYIDX38_I22:%.*]] = getelementptr inbounds float, ptr addrspace(258) addrspacecast (ptr @globalArrayAS0 to ptr addrspace(258)), i64 [[IDXPROM37_I21]]
; X86-NEXT:    [[L1:%.*]] = load float, ptr addrspace(258) [[ARRAYIDX38_I22]], align 16
; X86-NEXT:    ret void
;
entry:
  %mul32.i = shl nuw nsw i32 %idx, 8
  %add36.i = add nuw nsw i32 %mul32.i, 1024
  %idxprom37.i21 = zext i32 %add36.i to i64
  %arrayidx38.i22 = getelementptr inbounds float, ptr addrspace(258) addrspacecast (ptr @globalArrayAS0 to ptr addrspace(258)), i64 %idxprom37.i21
  %l1 = load float, ptr addrspace(258) %arrayidx38.i22, align 4
  ret void
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define amdgpu_kernel void @infer_AS04(i32 %idx) unnamed_addr align 2 {
; AMDGPU-LABEL: define amdgpu_kernel void @infer_AS04(
; AMDGPU-SAME: i32 [[IDX:%.*]]) unnamed_addr #[[ATTR0]] align 2 {
; AMDGPU-NEXT:  entry:
; AMDGPU-NEXT:    [[MUL32_I:%.*]] = shl nuw nsw i32 [[IDX]], 8
; AMDGPU-NEXT:    [[ADD36_I:%.*]] = add nuw nsw i32 [[MUL32_I]], 1024
; AMDGPU-NEXT:    [[IDXPROM37_I21:%.*]] = zext i32 [[ADD36_I]] to i64
; AMDGPU-NEXT:    [[ARRAYIDX38_I22:%.*]] = getelementptr inbounds float, ptr addrspace(270) addrspacecast (ptr @globalArrayAS0 to ptr addrspace(270)), i64 [[IDXPROM37_I21]]
; AMDGPU-NEXT:    [[L1:%.*]] = load float, ptr addrspace(270) [[ARRAYIDX38_I22]], align 16
; AMDGPU-NEXT:    ret void
;
; X86-LABEL: define amdgpu_kernel void @infer_AS04(
; X86-SAME: i32 [[IDX:%.*]]) unnamed_addr #[[ATTR0]] align 2 {
; X86-NEXT:  entry:
; X86-NEXT:    [[MUL32_I:%.*]] = shl nuw nsw i32 [[IDX]], 8
; X86-NEXT:    [[ADD36_I:%.*]] = add nuw nsw i32 [[MUL32_I]], 1024
; X86-NEXT:    [[IDXPROM37_I21:%.*]] = zext i32 [[ADD36_I]] to i64
; X86-NEXT:    [[ARRAYIDX38_I22:%.*]] = getelementptr inbounds float, ptr addrspace(270) addrspacecast (ptr @globalArrayAS0 to ptr addrspace(270)), i64 [[IDXPROM37_I21]]
; X86-NEXT:    [[L1:%.*]] = load float, ptr addrspace(270) [[ARRAYIDX38_I22]], align 16
; X86-NEXT:    ret void
;
entry:
  %mul32.i = shl nuw nsw i32 %idx, 8
  %add36.i = add nuw nsw i32 %mul32.i, 1024
  %idxprom37.i21 = zext i32 %add36.i to i64
  %arrayidx38.i22 = getelementptr inbounds float, ptr addrspace(270) addrspacecast (ptr @globalArrayAS0 to ptr addrspace(270)), i64 %idxprom37.i21
  %l1 = load float, ptr addrspace(270) %arrayidx38.i22, align 4
  ret void
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define amdgpu_kernel void @infer_AS05(i32 %idx) unnamed_addr align 2 {
; AMDGPU-LABEL: define amdgpu_kernel void @infer_AS05(
; AMDGPU-SAME: i32 [[IDX:%.*]]) unnamed_addr #[[ATTR0]] align 2 {
; AMDGPU-NEXT:  entry:
; AMDGPU-NEXT:    [[MUL32_I:%.*]] = shl nuw nsw i32 [[IDX]], 8
; AMDGPU-NEXT:    [[ADD36_I:%.*]] = add nuw nsw i32 [[MUL32_I]], 1024
; AMDGPU-NEXT:    [[IDXPROM37_I21:%.*]] = zext i32 [[ADD36_I]] to i64
; AMDGPU-NEXT:    [[ARRAYIDX38_I22:%.*]] = getelementptr inbounds float, ptr addrspace(271) addrspacecast (ptr @globalArrayAS0 to ptr addrspace(271)), i64 [[IDXPROM37_I21]]
; AMDGPU-NEXT:    [[L1:%.*]] = load float, ptr addrspace(271) [[ARRAYIDX38_I22]], align 16
; AMDGPU-NEXT:    ret void
;
; X86-LABEL: define amdgpu_kernel void @infer_AS05(
; X86-SAME: i32 [[IDX:%.*]]) unnamed_addr #[[ATTR0]] align 2 {
; X86-NEXT:  entry:
; X86-NEXT:    [[MUL32_I:%.*]] = shl nuw nsw i32 [[IDX]], 8
; X86-NEXT:    [[ADD36_I:%.*]] = add nuw nsw i32 [[MUL32_I]], 1024
; X86-NEXT:    [[IDXPROM37_I21:%.*]] = zext i32 [[ADD36_I]] to i64
; X86-NEXT:    [[ARRAYIDX38_I22:%.*]] = getelementptr inbounds float, ptr addrspace(271) addrspacecast (ptr @globalArrayAS0 to ptr addrspace(271)), i64 [[IDXPROM37_I21]]
; X86-NEXT:    [[L1:%.*]] = load float, ptr addrspace(271) [[ARRAYIDX38_I22]], align 16
; X86-NEXT:    ret void
;
entry:
  %mul32.i = shl nuw nsw i32 %idx, 8
  %add36.i = add nuw nsw i32 %mul32.i, 1024
  %idxprom37.i21 = zext i32 %add36.i to i64
  %arrayidx38.i22 = getelementptr inbounds float, ptr addrspace(271) addrspacecast (ptr @globalArrayAS0 to ptr addrspace(271)), i64 %idxprom37.i21
  %l1 = load float, ptr addrspace(271) %arrayidx38.i22, align 4
  ret void
}

; Function Attrs: alwaysinline convergent mustprogress nounwind
define amdgpu_kernel void @infer_AS06(i32 %idx) unnamed_addr align 2 {
; AMDGPU-LABEL: define amdgpu_kernel void @infer_AS06(
; AMDGPU-SAME: i32 [[IDX:%.*]]) unnamed_addr #[[ATTR0]] align 2 {
; AMDGPU-NEXT:  entry:
; AMDGPU-NEXT:    [[MUL32_I:%.*]] = shl nuw nsw i32 [[IDX]], 8
; AMDGPU-NEXT:    [[ADD36_I:%.*]] = add nuw nsw i32 [[MUL32_I]], 1024
; AMDGPU-NEXT:    [[IDXPROM37_I21:%.*]] = zext i32 [[ADD36_I]] to i64
; AMDGPU-NEXT:    [[ARRAYIDX38_I22:%.*]] = getelementptr inbounds float, ptr addrspace(272) addrspacecast (ptr @globalArrayAS0 to ptr addrspace(272)), i64 [[IDXPROM37_I21]]
; AMDGPU-NEXT:    [[L1:%.*]] = load float, ptr addrspace(272) [[ARRAYIDX38_I22]], align 16
; AMDGPU-NEXT:    ret void
;
; X86-LABEL: define amdgpu_kernel void @infer_AS06(
; X86-SAME: i32 [[IDX:%.*]]) unnamed_addr #[[ATTR0]] align 2 {
; X86-NEXT:  entry:
; X86-NEXT:    [[MUL32_I:%.*]] = shl nuw nsw i32 [[IDX]], 8
; X86-NEXT:    [[ADD36_I:%.*]] = add nuw nsw i32 [[MUL32_I]], 1024
; X86-NEXT:    [[IDXPROM37_I21:%.*]] = zext i32 [[ADD36_I]] to i64
; X86-NEXT:    [[ARRAYIDX38_I22:%.*]] = getelementptr inbounds float, ptr addrspace(272) addrspacecast (ptr @globalArrayAS0 to ptr addrspace(272)), i64 [[IDXPROM37_I21]]
; X86-NEXT:    [[L1:%.*]] = load float, ptr addrspace(272) [[ARRAYIDX38_I22]], align 16
; X86-NEXT:    ret void
;
entry:
  %mul32.i = shl nuw nsw i32 %idx, 8
  %add36.i = add nuw nsw i32 %mul32.i, 1024
  %idxprom37.i21 = zext i32 %add36.i to i64
  %arrayidx38.i22 = getelementptr inbounds float, ptr addrspace(272) addrspacecast (ptr @globalArrayAS0 to ptr addrspace(272)), i64 %idxprom37.i21
  %l1 = load float, ptr addrspace(272) %arrayidx38.i22, align 4
  ret void
}


; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i32 @llvm.amdgcn.workitem.id.x()
