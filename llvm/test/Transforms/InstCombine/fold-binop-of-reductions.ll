; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 5
; RUN: opt < %s -passes=instcombine -S | FileCheck %s
target datalayout = "E-p:64:64:64-a0:0:8-f32:32:32-f64:64:64-i1:8:8-i8:8:8-i16:16:16-i32:32:32-i64:32:64-v64:64:64-v128:128:128"

define i32 @add_of_reduce_add(<16 x i32> %v0, <16 x i32> %v1) {
; CHECK-LABEL: define i32 @add_of_reduce_add(
; CHECK-SAME: <16 x i32> [[V0:%.*]], <16 x i32> [[V1:%.*]]) {
; CHECK-NEXT:    [[V0_RED:%.*]] = tail call i32 @llvm.vector.reduce.add.v16i32(<16 x i32> [[V0]])
; CHECK-NEXT:    [[V1_RED:%.*]] = tail call i32 @llvm.vector.reduce.add.v16i32(<16 x i32> [[V1]])
; CHECK-NEXT:    [[RES:%.*]] = add i32 [[V0_RED]], [[V1_RED]]
; CHECK-NEXT:    ret i32 [[RES]]
;
  %v0_red = tail call i32 @llvm.vector.reduce.add.v16i32(<16 x i32> %v0)
  %v1_red = tail call i32 @llvm.vector.reduce.add.v16i32(<16 x i32> %v1)
  %res = add i32 %v0_red, %v1_red
  ret i32 %res
}

define i32 @sub_of_reduce_add(<16 x i32> %v0, <16 x i32> %v1) {
; CHECK-LABEL: define i32 @sub_of_reduce_add(
; CHECK-SAME: <16 x i32> [[V0:%.*]], <16 x i32> [[V1:%.*]]) {
; CHECK-NEXT:    [[TMP1:%.*]] = sub <16 x i32> [[V0]], [[V1]]
; CHECK-NEXT:    [[RES:%.*]] = call i32 @llvm.vector.reduce.add.v16i32(<16 x i32> [[TMP1]])
; CHECK-NEXT:    ret i32 [[RES]]
;
  %v0_red = tail call i32 @llvm.vector.reduce.add.v16i32(<16 x i32> %v0)
  %v1_red = tail call i32 @llvm.vector.reduce.add.v16i32(<16 x i32> %v1)
  %res = sub i32 %v0_red, %v1_red
  ret i32 %res
}

define i32 @mul_of_reduce_mul(<16 x i32> %v0, <16 x i32> %v1) {
; CHECK-LABEL: define i32 @mul_of_reduce_mul(
; CHECK-SAME: <16 x i32> [[V0:%.*]], <16 x i32> [[V1:%.*]]) {
; CHECK-NEXT:    [[V0_RED:%.*]] = tail call i32 @llvm.vector.reduce.mul.v16i32(<16 x i32> [[V0]])
; CHECK-NEXT:    [[V1_RED:%.*]] = tail call i32 @llvm.vector.reduce.mul.v16i32(<16 x i32> [[V1]])
; CHECK-NEXT:    [[RES:%.*]] = mul i32 [[V0_RED]], [[V1_RED]]
; CHECK-NEXT:    ret i32 [[RES]]
;
  %v0_red = tail call i32 @llvm.vector.reduce.mul.v16i32(<16 x i32> %v0)
  %v1_red = tail call i32 @llvm.vector.reduce.mul.v16i32(<16 x i32> %v1)
  %res = mul i32 %v0_red, %v1_red
  ret i32 %res
}

define i32 @and_of_reduce_and(<16 x i32> %v0, <16 x i32> %v1) {
; CHECK-LABEL: define i32 @and_of_reduce_and(
; CHECK-SAME: <16 x i32> [[V0:%.*]], <16 x i32> [[V1:%.*]]) {
; CHECK-NEXT:    [[V0_RED:%.*]] = tail call i32 @llvm.vector.reduce.and.v16i32(<16 x i32> [[V0]])
; CHECK-NEXT:    [[V1_RED:%.*]] = tail call i32 @llvm.vector.reduce.and.v16i32(<16 x i32> [[V1]])
; CHECK-NEXT:    [[RES:%.*]] = and i32 [[V0_RED]], [[V1_RED]]
; CHECK-NEXT:    ret i32 [[RES]]
;
  %v0_red = tail call i32 @llvm.vector.reduce.and.v16i32(<16 x i32> %v0)
  %v1_red = tail call i32 @llvm.vector.reduce.and.v16i32(<16 x i32> %v1)
  %res = and i32 %v0_red, %v1_red
  ret i32 %res
}

define i32 @or_of_reduce_or(<16 x i32> %v0, <16 x i32> %v1) {
; CHECK-LABEL: define i32 @or_of_reduce_or(
; CHECK-SAME: <16 x i32> [[V0:%.*]], <16 x i32> [[V1:%.*]]) {
; CHECK-NEXT:    [[V0_RED:%.*]] = tail call i32 @llvm.vector.reduce.or.v16i32(<16 x i32> [[V0]])
; CHECK-NEXT:    [[V1_RED:%.*]] = tail call i32 @llvm.vector.reduce.or.v16i32(<16 x i32> [[V1]])
; CHECK-NEXT:    [[RES:%.*]] = or i32 [[V0_RED]], [[V1_RED]]
; CHECK-NEXT:    ret i32 [[RES]]
;
  %v0_red = tail call i32 @llvm.vector.reduce.or.v16i32(<16 x i32> %v0)
  %v1_red = tail call i32 @llvm.vector.reduce.or.v16i32(<16 x i32> %v1)
  %res = or i32 %v0_red, %v1_red
  ret i32 %res
}

define i32 @xor_of_reduce_xor(<16 x i32> %v0, <16 x i32> %v1) {
; CHECK-LABEL: define i32 @xor_of_reduce_xor(
; CHECK-SAME: <16 x i32> [[V0:%.*]], <16 x i32> [[V1:%.*]]) {
; CHECK-NEXT:    [[V0_RED:%.*]] = tail call i32 @llvm.vector.reduce.xor.v16i32(<16 x i32> [[V0]])
; CHECK-NEXT:    [[V1_RED:%.*]] = tail call i32 @llvm.vector.reduce.xor.v16i32(<16 x i32> [[V1]])
; CHECK-NEXT:    [[RES:%.*]] = xor i32 [[V0_RED]], [[V1_RED]]
; CHECK-NEXT:    ret i32 [[RES]]
;
  %v0_red = tail call i32 @llvm.vector.reduce.xor.v16i32(<16 x i32> %v0)
  %v1_red = tail call i32 @llvm.vector.reduce.xor.v16i32(<16 x i32> %v1)
  %res = xor i32 %v0_red, %v1_red
  ret i32 %res
}

define i32 @add_of_reduce_mul(<16 x i32> %v0, <16 x i32> %v1) {
; CHECK-LABEL: define i32 @add_of_reduce_mul(
; CHECK-SAME: <16 x i32> [[V0:%.*]], <16 x i32> [[V1:%.*]]) {
; CHECK-NEXT:    [[V0_RED:%.*]] = tail call i32 @llvm.vector.reduce.mul.v16i32(<16 x i32> [[V0]])
; CHECK-NEXT:    [[V1_RED:%.*]] = tail call i32 @llvm.vector.reduce.mul.v16i32(<16 x i32> [[V1]])
; CHECK-NEXT:    [[RES:%.*]] = xor i32 [[V0_RED]], [[V1_RED]]
; CHECK-NEXT:    ret i32 [[RES]]
;
  %v0_red = tail call i32 @llvm.vector.reduce.mul.v16i32(<16 x i32> %v0)
  %v1_red = tail call i32 @llvm.vector.reduce.mul.v16i32(<16 x i32> %v1)
  %res = xor i32 %v0_red, %v1_red
  ret i32 %res
}
