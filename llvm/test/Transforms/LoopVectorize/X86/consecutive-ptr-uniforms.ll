; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 4
; REQUIRES: asserts
; RUN: opt < %s -aa-pipeline=basic-aa -passes=loop-vectorize,instcombine -S -debug-only=loop-vectorize -disable-output -print-after=instcombine 2>&1 | FileCheck %s
; RUN: opt < %s -passes=loop-vectorize -force-vector-width=2 -S | FileCheck %s -check-prefix=FORCE

target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

; CHECK-LABEL: PR31671
;
; Check a pointer in which one of its uses is consecutive-like and another of
; its uses is non-consecutive-like. In the test case below, %tmp3 is the
; pointer operand of an interleaved load, making it consecutive-like. However,
; it is also the pointer operand of a non-interleaved store that will become a
; scatter operation. %tmp3 (and the induction variable) should not be marked
; uniform-after-vectorization.
;
; CHECK:       LV: Found uniform instruction: %tmp0 = getelementptr inbounds %data, ptr %d, i64 0, i32 3, i64 %i
; CHECK-NOT:   LV: Found uniform instruction: %tmp3 = getelementptr inbounds %data, ptr %d, i64 0, i32 0, i64 %i
; CHECK-NOT:   LV: Found uniform instruction: %i = phi i64 [ %i.next, %for.body ], [ 0, %entry ]
; CHECK-NOT:   LV: Found uniform instruction: %i.next = add nuw nsw i64 %i, 5

%data = type { [32000 x float], [3 x i32], [4 x i8], [32000 x float] }

define void @PR31671(float %x, ptr %d) #0 {
; CHECK-LABEL: define void @PR31671(
; CHECK-SAME: float [[X:%.*]], ptr [[D:%.*]]) #[[ATTR0:[0-9]+]] {
; CHECK-NEXT:  entry:
; CHECK-NEXT:    br i1 false, label [[SCALAR_PH:%.*]], label [[VECTOR_PH:%.*]]
; CHECK:       vector.ph:
; CHECK-NEXT:    [[BROADCAST_SPLATINSERT:%.*]] = insertelement <16 x float> poison, float [[X]], i64 0
; CHECK-NEXT:    [[BROADCAST_SPLAT:%.*]] = shufflevector <16 x float> [[BROADCAST_SPLATINSERT]], <16 x float> poison, <16 x i32> zeroinitializer
; CHECK-NEXT:    br label [[VECTOR_BODY:%.*]]
; CHECK:       vector.body:
; CHECK-NEXT:    [[INDEX:%.*]] = phi i64 [ 0, [[VECTOR_PH]] ], [ [[INDEX_NEXT:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[VEC_IND:%.*]] = phi <16 x i64> [ <i64 0, i64 5, i64 10, i64 15, i64 20, i64 25, i64 30, i64 35, i64 40, i64 45, i64 50, i64 55, i64 60, i64 65, i64 70, i64 75>, [[VECTOR_PH]] ], [ [[TMP5:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[OFFSET_IDX:%.*]] = mul i64 [[INDEX]], 5
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr inbounds [[DATA:%.*]], ptr [[D]], i64 0, i32 3, i64 [[OFFSET_IDX]]
; CHECK-NEXT:    [[WIDE_VEC:%.*]] = load <80 x float>, ptr [[TMP0]], align 4
; CHECK-NEXT:    [[STRIDED_VEC:%.*]] = shufflevector <80 x float> [[WIDE_VEC]], <80 x float> poison, <16 x i32> <i32 0, i32 5, i32 10, i32 15, i32 20, i32 25, i32 30, i32 35, i32 40, i32 45, i32 50, i32 55, i32 60, i32 65, i32 70, i32 75>
; CHECK-NEXT:    [[TMP1:%.*]] = fmul <16 x float> [[BROADCAST_SPLAT]], [[STRIDED_VEC]]
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr inbounds [[DATA]], ptr [[D]], i64 0, i32 0, <16 x i64> [[VEC_IND]]
; CHECK-NEXT:    [[TMP3:%.*]] = extractelement <16 x ptr> [[TMP2]], i64 0
; CHECK-NEXT:    [[WIDE_VEC1:%.*]] = load <80 x float>, ptr [[TMP3]], align 4
; CHECK-NEXT:    [[STRIDED_VEC2:%.*]] = shufflevector <80 x float> [[WIDE_VEC1]], <80 x float> poison, <16 x i32> <i32 0, i32 5, i32 10, i32 15, i32 20, i32 25, i32 30, i32 35, i32 40, i32 45, i32 50, i32 55, i32 60, i32 65, i32 70, i32 75>
; CHECK-NEXT:    [[TMP4:%.*]] = fadd <16 x float> [[STRIDED_VEC2]], [[TMP1]]
; CHECK-NEXT:    call void @llvm.masked.scatter.v16f32.v16p0(<16 x float> [[TMP4]], <16 x ptr> [[TMP2]], i32 4, <16 x i1> <i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true>)
; CHECK-NEXT:    [[INDEX_NEXT]] = add nuw i64 [[INDEX]], 16
; CHECK-NEXT:    [[TMP5]] = add <16 x i64> [[VEC_IND]], <i64 80, i64 80, i64 80, i64 80, i64 80, i64 80, i64 80, i64 80, i64 80, i64 80, i64 80, i64 80, i64 80, i64 80, i64 80, i64 80>
; CHECK-NEXT:    [[TMP6:%.*]] = icmp eq i64 [[INDEX_NEXT]], 6384
; CHECK-NEXT:    br i1 [[TMP6]], label [[MIDDLE_BLOCK:%.*]], label [[VECTOR_BODY]], !llvm.loop [[LOOP0:![0-9]+]]
; CHECK:       middle.block:
; CHECK-NEXT:    br label [[SCALAR_PH]]
; CHECK:       scalar.ph:
; CHECK-NEXT:    br label [[FOR_BODY:%.*]]
; CHECK:       for.body:
; CHECK-NEXT:    [[I:%.*]] = phi i64 [ [[I_NEXT:%.*]], [[FOR_BODY]] ], [ 31920, [[SCALAR_PH]] ]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr inbounds [[DATA]], ptr [[D]], i64 0, i32 3, i64 [[I]]
; CHECK-NEXT:    [[TMP1:%.*]] = load float, ptr [[TMP0]], align 4
; CHECK-NEXT:    [[TMP2:%.*]] = fmul float [[TMP1]], [[X]]
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr inbounds [[DATA]], ptr [[D]], i64 0, i32 0, i64 [[I]]
; CHECK-NEXT:    [[TMP4:%.*]] = load float, ptr [[TMP3]], align 4
; CHECK-NEXT:    [[TMP5:%.*]] = fadd float [[TMP4]], [[TMP2]]
; CHECK-NEXT:    store float [[TMP5]], ptr [[TMP3]], align 4
; CHECK-NEXT:    [[I_NEXT]] = add nuw nsw i64 [[I]], 5
; CHECK-NEXT:    [[COND:%.*]] = icmp ult i64 [[I]], 31995
; CHECK-NEXT:    br i1 [[COND]], label [[FOR_BODY]], label [[FOR_END:%.*]], !llvm.loop [[LOOP3:![0-9]+]]
; CHECK:       for.end:
; CHECK-NEXT:    ret void
;
; FORCE-LABEL: define void @PR31671(
; FORCE-SAME: float [[X:%.*]], ptr [[D:%.*]]) #[[ATTR0:[0-9]+]] {
; FORCE-NEXT:  entry:
; FORCE-NEXT:    br i1 false, label [[SCALAR_PH:%.*]], label [[VECTOR_PH:%.*]]
; FORCE:       vector.ph:
; FORCE-NEXT:    [[BROADCAST_SPLATINSERT:%.*]] = insertelement <2 x float> poison, float [[X]], i64 0
; FORCE-NEXT:    [[BROADCAST_SPLAT:%.*]] = shufflevector <2 x float> [[BROADCAST_SPLATINSERT]], <2 x float> poison, <2 x i32> zeroinitializer
; FORCE-NEXT:    br label [[VECTOR_BODY:%.*]]
; FORCE:       vector.body:
; FORCE-NEXT:    [[INDEX:%.*]] = phi i64 [ 0, [[VECTOR_PH]] ], [ [[INDEX_NEXT:%.*]], [[VECTOR_BODY]] ]
; FORCE-NEXT:    [[OFFSET_IDX:%.*]] = mul i64 [[INDEX]], 5
; FORCE-NEXT:    [[TMP0:%.*]] = add i64 [[OFFSET_IDX]], 0
; FORCE-NEXT:    [[TMP1:%.*]] = add i64 [[OFFSET_IDX]], 5
; FORCE-NEXT:    [[TMP2:%.*]] = add i64 [[OFFSET_IDX]], 10
; FORCE-NEXT:    [[TMP3:%.*]] = add i64 [[OFFSET_IDX]], 15
; FORCE-NEXT:    [[TMP4:%.*]] = add i64 [[OFFSET_IDX]], 20
; FORCE-NEXT:    [[TMP5:%.*]] = add i64 [[OFFSET_IDX]], 25
; FORCE-NEXT:    [[TMP6:%.*]] = add i64 [[OFFSET_IDX]], 30
; FORCE-NEXT:    [[TMP7:%.*]] = add i64 [[OFFSET_IDX]], 35
; FORCE-NEXT:    [[TMP8:%.*]] = getelementptr inbounds [[DATA:%.*]], ptr [[D]], i64 0, i32 3, i64 [[TMP0]]
; FORCE-NEXT:    [[TMP9:%.*]] = getelementptr inbounds [[DATA]], ptr [[D]], i64 0, i32 3, i64 [[TMP2]]
; FORCE-NEXT:    [[TMP10:%.*]] = getelementptr inbounds [[DATA]], ptr [[D]], i64 0, i32 3, i64 [[TMP4]]
; FORCE-NEXT:    [[TMP11:%.*]] = getelementptr inbounds [[DATA]], ptr [[D]], i64 0, i32 3, i64 [[TMP6]]
; FORCE-NEXT:    [[TMP12:%.*]] = getelementptr inbounds float, ptr [[TMP8]], i32 0
; FORCE-NEXT:    [[TMP13:%.*]] = getelementptr inbounds float, ptr [[TMP9]], i32 0
; FORCE-NEXT:    [[TMP14:%.*]] = getelementptr inbounds float, ptr [[TMP10]], i32 0
; FORCE-NEXT:    [[TMP15:%.*]] = getelementptr inbounds float, ptr [[TMP11]], i32 0
; FORCE-NEXT:    [[WIDE_VEC:%.*]] = load <10 x float>, ptr [[TMP12]], align 4
; FORCE-NEXT:    [[WIDE_VEC1:%.*]] = load <10 x float>, ptr [[TMP13]], align 4
; FORCE-NEXT:    [[WIDE_VEC2:%.*]] = load <10 x float>, ptr [[TMP14]], align 4
; FORCE-NEXT:    [[WIDE_VEC3:%.*]] = load <10 x float>, ptr [[TMP15]], align 4
; FORCE-NEXT:    [[STRIDED_VEC:%.*]] = shufflevector <10 x float> [[WIDE_VEC]], <10 x float> poison, <2 x i32> <i32 0, i32 5>
; FORCE-NEXT:    [[STRIDED_VEC4:%.*]] = shufflevector <10 x float> [[WIDE_VEC1]], <10 x float> poison, <2 x i32> <i32 0, i32 5>
; FORCE-NEXT:    [[STRIDED_VEC5:%.*]] = shufflevector <10 x float> [[WIDE_VEC2]], <10 x float> poison, <2 x i32> <i32 0, i32 5>
; FORCE-NEXT:    [[STRIDED_VEC6:%.*]] = shufflevector <10 x float> [[WIDE_VEC3]], <10 x float> poison, <2 x i32> <i32 0, i32 5>
; FORCE-NEXT:    [[TMP16:%.*]] = fmul <2 x float> [[BROADCAST_SPLAT]], [[STRIDED_VEC]]
; FORCE-NEXT:    [[TMP17:%.*]] = fmul <2 x float> [[BROADCAST_SPLAT]], [[STRIDED_VEC4]]
; FORCE-NEXT:    [[TMP18:%.*]] = fmul <2 x float> [[BROADCAST_SPLAT]], [[STRIDED_VEC5]]
; FORCE-NEXT:    [[TMP19:%.*]] = fmul <2 x float> [[BROADCAST_SPLAT]], [[STRIDED_VEC6]]
; FORCE-NEXT:    [[TMP20:%.*]] = getelementptr inbounds [[DATA]], ptr [[D]], i64 0, i32 0, i64 [[TMP0]]
; FORCE-NEXT:    [[TMP21:%.*]] = getelementptr inbounds [[DATA]], ptr [[D]], i64 0, i32 0, i64 [[TMP1]]
; FORCE-NEXT:    [[TMP22:%.*]] = getelementptr inbounds [[DATA]], ptr [[D]], i64 0, i32 0, i64 [[TMP2]]
; FORCE-NEXT:    [[TMP23:%.*]] = getelementptr inbounds [[DATA]], ptr [[D]], i64 0, i32 0, i64 [[TMP3]]
; FORCE-NEXT:    [[TMP24:%.*]] = getelementptr inbounds [[DATA]], ptr [[D]], i64 0, i32 0, i64 [[TMP4]]
; FORCE-NEXT:    [[TMP25:%.*]] = getelementptr inbounds [[DATA]], ptr [[D]], i64 0, i32 0, i64 [[TMP5]]
; FORCE-NEXT:    [[TMP26:%.*]] = getelementptr inbounds [[DATA]], ptr [[D]], i64 0, i32 0, i64 [[TMP6]]
; FORCE-NEXT:    [[TMP27:%.*]] = getelementptr inbounds [[DATA]], ptr [[D]], i64 0, i32 0, i64 [[TMP7]]
; FORCE-NEXT:    [[TMP28:%.*]] = getelementptr inbounds float, ptr [[TMP20]], i32 0
; FORCE-NEXT:    [[TMP29:%.*]] = getelementptr inbounds float, ptr [[TMP22]], i32 0
; FORCE-NEXT:    [[TMP30:%.*]] = getelementptr inbounds float, ptr [[TMP24]], i32 0
; FORCE-NEXT:    [[TMP31:%.*]] = getelementptr inbounds float, ptr [[TMP26]], i32 0
; FORCE-NEXT:    [[WIDE_VEC7:%.*]] = load <10 x float>, ptr [[TMP28]], align 4
; FORCE-NEXT:    [[WIDE_VEC8:%.*]] = load <10 x float>, ptr [[TMP29]], align 4
; FORCE-NEXT:    [[WIDE_VEC9:%.*]] = load <10 x float>, ptr [[TMP30]], align 4
; FORCE-NEXT:    [[WIDE_VEC10:%.*]] = load <10 x float>, ptr [[TMP31]], align 4
; FORCE-NEXT:    [[STRIDED_VEC11:%.*]] = shufflevector <10 x float> [[WIDE_VEC7]], <10 x float> poison, <2 x i32> <i32 0, i32 5>
; FORCE-NEXT:    [[STRIDED_VEC12:%.*]] = shufflevector <10 x float> [[WIDE_VEC8]], <10 x float> poison, <2 x i32> <i32 0, i32 5>
; FORCE-NEXT:    [[STRIDED_VEC13:%.*]] = shufflevector <10 x float> [[WIDE_VEC9]], <10 x float> poison, <2 x i32> <i32 0, i32 5>
; FORCE-NEXT:    [[STRIDED_VEC14:%.*]] = shufflevector <10 x float> [[WIDE_VEC10]], <10 x float> poison, <2 x i32> <i32 0, i32 5>
; FORCE-NEXT:    [[TMP32:%.*]] = fadd <2 x float> [[STRIDED_VEC11]], [[TMP16]]
; FORCE-NEXT:    [[TMP33:%.*]] = fadd <2 x float> [[STRIDED_VEC12]], [[TMP17]]
; FORCE-NEXT:    [[TMP34:%.*]] = fadd <2 x float> [[STRIDED_VEC13]], [[TMP18]]
; FORCE-NEXT:    [[TMP35:%.*]] = fadd <2 x float> [[STRIDED_VEC14]], [[TMP19]]
; FORCE-NEXT:    [[TMP36:%.*]] = extractelement <2 x float> [[TMP32]], i32 0
; FORCE-NEXT:    store float [[TMP36]], ptr [[TMP20]], align 4
; FORCE-NEXT:    [[TMP37:%.*]] = extractelement <2 x float> [[TMP32]], i32 1
; FORCE-NEXT:    store float [[TMP37]], ptr [[TMP21]], align 4
; FORCE-NEXT:    [[TMP38:%.*]] = extractelement <2 x float> [[TMP33]], i32 0
; FORCE-NEXT:    store float [[TMP38]], ptr [[TMP22]], align 4
; FORCE-NEXT:    [[TMP39:%.*]] = extractelement <2 x float> [[TMP33]], i32 1
; FORCE-NEXT:    store float [[TMP39]], ptr [[TMP23]], align 4
; FORCE-NEXT:    [[TMP40:%.*]] = extractelement <2 x float> [[TMP34]], i32 0
; FORCE-NEXT:    store float [[TMP40]], ptr [[TMP24]], align 4
; FORCE-NEXT:    [[TMP41:%.*]] = extractelement <2 x float> [[TMP34]], i32 1
; FORCE-NEXT:    store float [[TMP41]], ptr [[TMP25]], align 4
; FORCE-NEXT:    [[TMP42:%.*]] = extractelement <2 x float> [[TMP35]], i32 0
; FORCE-NEXT:    store float [[TMP42]], ptr [[TMP26]], align 4
; FORCE-NEXT:    [[TMP43:%.*]] = extractelement <2 x float> [[TMP35]], i32 1
; FORCE-NEXT:    store float [[TMP43]], ptr [[TMP27]], align 4
; FORCE-NEXT:    [[INDEX_NEXT]] = add nuw i64 [[INDEX]], 8
; FORCE-NEXT:    [[TMP44:%.*]] = icmp eq i64 [[INDEX_NEXT]], 6392
; FORCE-NEXT:    br i1 [[TMP44]], label [[MIDDLE_BLOCK:%.*]], label [[VECTOR_BODY]], !llvm.loop [[LOOP0:![0-9]+]]
; FORCE:       middle.block:
; FORCE-NEXT:    br label [[SCALAR_PH]]
; FORCE:       scalar.ph:
; FORCE-NEXT:    [[BC_RESUME_VAL:%.*]] = phi i64 [ 31960, [[MIDDLE_BLOCK]] ], [ 0, [[ENTRY:%.*]] ]
; FORCE-NEXT:    br label [[FOR_BODY:%.*]]
; FORCE:       for.body:
; FORCE-NEXT:    [[I:%.*]] = phi i64 [ [[I_NEXT:%.*]], [[FOR_BODY]] ], [ [[BC_RESUME_VAL]], [[SCALAR_PH]] ]
; FORCE-NEXT:    [[TMP0:%.*]] = getelementptr inbounds [[DATA]], ptr [[D]], i64 0, i32 3, i64 [[I]]
; FORCE-NEXT:    [[TMP1:%.*]] = load float, ptr [[TMP0]], align 4
; FORCE-NEXT:    [[TMP2:%.*]] = fmul float [[X]], [[TMP1]]
; FORCE-NEXT:    [[TMP3:%.*]] = getelementptr inbounds [[DATA]], ptr [[D]], i64 0, i32 0, i64 [[I]]
; FORCE-NEXT:    [[TMP4:%.*]] = load float, ptr [[TMP3]], align 4
; FORCE-NEXT:    [[TMP5:%.*]] = fadd float [[TMP4]], [[TMP2]]
; FORCE-NEXT:    store float [[TMP5]], ptr [[TMP3]], align 4
; FORCE-NEXT:    [[I_NEXT]] = add nuw nsw i64 [[I]], 5
; FORCE-NEXT:    [[COND:%.*]] = icmp slt i64 [[I_NEXT]], 32000
; FORCE-NEXT:    br i1 [[COND]], label [[FOR_BODY]], label [[FOR_END:%.*]], !llvm.loop [[LOOP3:![0-9]+]]
; FORCE:       for.end:
; FORCE-NEXT:    ret void
;
entry:
  br label %for.body

for.body:
  %i = phi i64 [ %i.next, %for.body ], [ 0, %entry ]
  %tmp0 = getelementptr inbounds %data, ptr %d, i64 0, i32 3, i64 %i
  %tmp1 = load float, ptr %tmp0, align 4
  %tmp2 = fmul float %x, %tmp1
  %tmp3 = getelementptr inbounds %data, ptr %d, i64 0, i32 0, i64 %i
  %tmp4 = load float, ptr %tmp3, align 4
  %tmp5 = fadd float %tmp4, %tmp2
  store float %tmp5, ptr %tmp3, align 4
  %i.next = add nuw nsw i64 %i, 5
  %cond = icmp slt i64 %i.next, 32000
  br i1 %cond, label %for.body, label %for.end

for.end:
  ret void
}

attributes #0 = { "target-cpu"="knl" }

; CHECK-LABEL: PR40816
;
; Check that scalar with predication instructions are not considered uniform
; after vectorization, because that results in replicating a region instead of
; having a single instance (out of VF). The predication stems from a tiny count
; of 3 leading to folding the tail by masking using icmp ule <i, i+1> <= <2, 2>.
;
; CHECK:     LV: Found trip count: 3
; CHECK:     LV: Found uniform instruction:   {{%.*}} = icmp eq i32 {{%.*}}, 0
; CHECK-NOT: LV: Found uniform instruction:   {{%.*}} = load i32, ptr {{%.*}}, align 1
; CHECK:     LV: Found not uniform being ScalarWithPredication:  {{%.*}} = load i32, ptr {{%.*}}, align 1
;
@a = internal constant [3 x i32] [i32 7, i32 7, i32 0], align 1
@b = external global i32, align 1

define void @PR40816() #1 {
; CHECK-LABEL: define void @PR40816(
; CHECK-SAME: ) #[[ATTR1:[0-9]+]] {
; CHECK-NEXT:  entry:
; CHECK-NEXT:    br label [[FOR_BODY:%.*]]
; CHECK:       for.body:
; CHECK-NEXT:    [[TMP0:%.*]] = phi i32 [ 0, [[ENTRY:%.*]] ], [ [[INC:%.*]], [[FOR_BODY]] ]
; CHECK-NEXT:    store i32 [[TMP0]], ptr @b, align 1
; CHECK-NEXT:    [[CMP2:%.*]] = icmp eq i32 [[TMP0]], 2
; CHECK-NEXT:    [[INC]] = add nuw nsw i32 [[TMP0]], 1
; CHECK-NEXT:    br i1 [[CMP2]], label [[RETURN:%.*]], label [[FOR_BODY]]
; CHECK:       return:
; CHECK-NEXT:    ret void
;
; FORCE-LABEL: define void @PR40816(
; FORCE-SAME: ) #[[ATTR1:[0-9]+]] {
; FORCE-NEXT:  entry:
; FORCE-NEXT:    br i1 false, label [[SCALAR_PH:%.*]], label [[VECTOR_PH:%.*]]
; FORCE:       vector.ph:
; FORCE-NEXT:    br label [[VECTOR_BODY:%.*]]
; FORCE:       vector.body:
; FORCE-NEXT:    [[INDEX:%.*]] = phi i32 [ 0, [[VECTOR_PH]] ], [ [[INDEX_NEXT:%.*]], [[PRED_STORE_CONTINUE2:%.*]] ]
; FORCE-NEXT:    [[VEC_IND:%.*]] = phi <2 x i32> [ <i32 0, i32 1>, [[VECTOR_PH]] ], [ [[TMP5:%.*]], [[PRED_STORE_CONTINUE2]] ]
; FORCE-NEXT:    [[TMP0:%.*]] = icmp ule <2 x i32> [[VEC_IND]], <i32 2, i32 2>
; FORCE-NEXT:    [[TMP1:%.*]] = extractelement <2 x i1> [[TMP0]], i32 0
; FORCE-NEXT:    br i1 [[TMP1]], label [[PRED_STORE_IF:%.*]], label [[PRED_STORE_CONTINUE:%.*]]
; FORCE:       pred.store.if:
; FORCE-NEXT:    [[TMP2:%.*]] = add i32 [[INDEX]], 0
; FORCE-NEXT:    store i32 [[TMP2]], ptr @b, align 1
; FORCE-NEXT:    br label [[PRED_STORE_CONTINUE]]
; FORCE:       pred.store.continue:
; FORCE-NEXT:    [[TMP3:%.*]] = extractelement <2 x i1> [[TMP0]], i32 1
; FORCE-NEXT:    br i1 [[TMP3]], label [[PRED_STORE_IF1:%.*]], label [[PRED_STORE_CONTINUE2]]
; FORCE:       pred.store.if1:
; FORCE-NEXT:    [[TMP4:%.*]] = add i32 [[INDEX]], 1
; FORCE-NEXT:    store i32 [[TMP4]], ptr @b, align 1
; FORCE-NEXT:    br label [[PRED_STORE_CONTINUE2]]
; FORCE:       pred.store.continue2:
; FORCE-NEXT:    [[INDEX_NEXT]] = add i32 [[INDEX]], 2
; FORCE-NEXT:    [[TMP5]] = add <2 x i32> [[VEC_IND]], <i32 2, i32 2>
; FORCE-NEXT:    [[TMP6:%.*]] = icmp eq i32 [[INDEX_NEXT]], 4
; FORCE-NEXT:    br i1 [[TMP6]], label [[MIDDLE_BLOCK:%.*]], label [[VECTOR_BODY]], !llvm.loop [[LOOP4:![0-9]+]]
; FORCE:       middle.block:
; FORCE-NEXT:    br i1 true, label [[RETURN:%.*]], label [[SCALAR_PH]]
; FORCE:       scalar.ph:
; FORCE-NEXT:    [[BC_RESUME_VAL:%.*]] = phi i32 [ 4, [[MIDDLE_BLOCK]] ], [ 0, [[ENTRY:%.*]] ]
; FORCE-NEXT:    br label [[FOR_BODY:%.*]]
; FORCE:       for.body:
; FORCE-NEXT:    [[TMP7:%.*]] = phi i32 [ [[BC_RESUME_VAL]], [[SCALAR_PH]] ], [ [[INC:%.*]], [[FOR_BODY]] ]
; FORCE-NEXT:    store i32 [[TMP7]], ptr @b, align 1
; FORCE-NEXT:    [[ARRAYIDX1:%.*]] = getelementptr inbounds [3 x i32], ptr @a, i32 0, i32 [[TMP7]]
; FORCE-NEXT:    [[TMP8:%.*]] = load i32, ptr [[ARRAYIDX1]], align 1
; FORCE-NEXT:    [[CMP2:%.*]] = icmp eq i32 [[TMP8]], 0
; FORCE-NEXT:    [[INC]] = add nuw nsw i32 [[TMP7]], 1
; FORCE-NEXT:    br i1 [[CMP2]], label [[RETURN]], label [[FOR_BODY]], !llvm.loop [[LOOP5:![0-9]+]]
; FORCE:       return:
; FORCE-NEXT:    ret void
;
entry:
  br label %for.body

for.body:                                         ; preds = %for.body, %entry
  %0 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  store i32 %0, ptr @b, align 1
  %arrayidx1 = getelementptr inbounds [3 x i32], ptr @a, i32 0, i32 %0
  %1 = load i32, ptr %arrayidx1, align 1
  %cmp2 = icmp eq i32 %1, 0
  %inc = add nuw nsw i32 %0, 1
  br i1 %cmp2, label %return, label %for.body

return:                                           ; preds = %for.body
  ret void
}

attributes #1 = { "target-cpu"="core2" }
;.
; FORCE: [[LOOP0]] = distinct !{[[LOOP0]], [[META1:![0-9]+]], [[META2:![0-9]+]]}
; FORCE: [[META1]] = !{!"llvm.loop.isvectorized", i32 1}
; FORCE: [[META2]] = !{!"llvm.loop.unroll.runtime.disable"}
; FORCE: [[LOOP3]] = distinct !{[[LOOP3]], [[META2]], [[META1]]}
; FORCE: [[LOOP4]] = distinct !{[[LOOP4]], [[META1]], [[META2]]}
; FORCE: [[LOOP5]] = distinct !{[[LOOP5]], [[META2]], [[META1]]}
;.
